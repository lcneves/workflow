{"id":"workflow-1rq","title":"Add specVersion to run schema","description":"Add specVersion: z.string().optional() to WorkflowRunBaseSchema in /packages/world/src/runs.ts","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-05T23:39:38.980679-08:00","created_by":"pranaygp","updated_at":"2026-01-05T23:41:19.84279-08:00","closed_at":"2026-01-05T23:41:19.84279-08:00","close_reason":"Closed","dependencies":[{"issue_id":"workflow-1rq","depends_on_id":"workflow-ov5","type":"blocks","created_at":"2026-01-05T23:39:49.429011-08:00","created_by":"pranaygp"}]}
{"id":"workflow-1wn","title":"Fix unit test failures in CI","description":"Unit tests failing in CI. See https://github.com/vercel/workflow/actions/runs/20739023408/job/59542030712","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-05T21:33:58.544375-08:00","created_by":"pranaygp","updated_at":"2026-01-05T21:44:18.573493-08:00","closed_at":"2026-01-05T21:44:18.573498-08:00","close_reason":"Updated world-local tests for hook_conflict event behavior"}
{"id":"workflow-2hf","title":"Add unit tests for hook_conflict handling","description":"Add tests to workflow.test.ts and world-testing package to test the new hook_conflict event handling behavior. This is separate from the e2e test that was added.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-05T21:07:56.909784-08:00","created_by":"pranaygp","updated_at":"2026-01-05T21:22:40.822599-08:00","closed_at":"2026-01-05T21:22:40.822599-08:00","close_reason":"Added hook_conflict tests to workflow.test.ts and fixed world-postgres test"}
{"id":"workflow-2oq","title":"Add specVersion property for backwards compatibility","description":"Add specVersion property to World interface using npm package version. Store the spec version on runs when created. Server handles backwards compatibility routing.\n\nFiles to modify:\n- /packages/world/src/interfaces.ts - Add specVersion to World interface\n- /packages/world/src/runs.ts - Add specVersion to run schema\n- /packages/world/src/events.ts - Add specVersion to run_created event\n- /packages/world/package.json - Add genversion scripts\n- /packages/world/.gitignore - Add src/version.ts\n- world-vercel, world-local, world-postgres, world-testing - Set specVersion from version","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-05T23:38:08.579156-08:00","created_by":"pranaygp","updated_at":"2026-01-05T23:40:03.664499-08:00","closed_at":"2026-01-05T23:40:03.664499-08:00","close_reason":"Tracked by individual tasks: workflow-ov5, workflow-66v, workflow-1rq, workflow-nld, workflow-dg3, workflow-klf, workflow-ot2, workflow-t1f, workflow-tmc"}
{"id":"workflow-66v","title":"Add genversion to @workflow/world package","description":"Add genversion to build scripts in /packages/world/package.json and add src/version.ts to .gitignore","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-05T23:39:38.843372-08:00","created_by":"pranaygp","updated_at":"2026-01-05T23:40:57.593767-08:00","closed_at":"2026-01-05T23:40:57.593767-08:00","close_reason":"Closed"}
{"id":"workflow-a7i","title":"Improve hook-conflict.mdx error guide","description":"Update the hook-conflict.mdx error documentation:\n1. Remove the redundant third point in 'Why This Happens' section ('Token generation is not unique')\n2. Add an example showing how to handle the WorkflowRuntimeError when awaiting a conflicting hook - users can catch and handle hook conflicts in their workflow code","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-05T21:08:01.8258-08:00","created_by":"pranaygp","updated_at":"2026-01-05T21:25:42.996468-08:00","closed_at":"2026-01-05T21:25:42.996468-08:00","close_reason":"Improved hook-conflict.mdx: removed redundant point, added error handling example"}
{"id":"workflow-ajl","title":"Fix docs validation failure","description":"Docs validation is failing on CI. See https://github.com/vercel/workflow/runs/59542016144","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-05T21:33:15.924947-08:00","created_by":"pranaygp","updated_at":"2026-01-05T21:44:18.476423-08:00","closed_at":"2026-01-05T21:44:18.476427-08:00","close_reason":"Fixed broken link in hook-conflict.mdx and added to errors index"}
{"id":"workflow-dg3","title":"Update world-vercel to set specVersion","description":"Add genversion and set specVersion property in world-vercel implementation","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-05T23:39:39.260724-08:00","created_by":"pranaygp","updated_at":"2026-01-05T23:43:10.608481-08:00","closed_at":"2026-01-05T23:43:10.608481-08:00","close_reason":"Closed","dependencies":[{"issue_id":"workflow-dg3","depends_on_id":"workflow-ov5","type":"blocks","created_at":"2026-01-05T23:39:49.658856-08:00","created_by":"pranaygp"},{"issue_id":"workflow-dg3","depends_on_id":"workflow-66v","type":"blocks","created_at":"2026-01-05T23:39:49.691337-08:00","created_by":"pranaygp"}]}
{"id":"workflow-dmf","title":"Remove redundant message from hook_conflict eventData","description":"The hook_conflict event type already implies the error, so the message field in eventData is redundant. Remove it from both workflow-server and the client-side packages (world-local, world-postgres, world).","status":"closed","priority":2,"issue_type":"chore","created_at":"2026-01-05T21:07:52.66597-08:00","created_by":"pranaygp","updated_at":"2026-01-05T21:18:33.334884-08:00","closed_at":"2026-01-05T21:18:33.334884-08:00","close_reason":"Removed redundant message field from hook_conflict eventData across all implementations. PR #171 created for workflow-server."}
{"id":"workflow-jx6","title":"update world-vercel and workflow-server to implement the new hook_conflict event","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-05T20:45:35.522865-08:00","created_by":"pranaygp","updated_at":"2026-01-05T20:59:16.812818-08:00","closed_at":"2026-01-05T20:59:16.812818-08:00","close_reason":"Implemented hook_conflict event in workflow-server"}
{"id":"workflow-klf","title":"Update world-local to set specVersion","description":"Set specVersion property in world-local implementation","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-05T23:39:39.409503-08:00","created_by":"pranaygp","updated_at":"2026-01-05T23:43:10.609805-08:00","closed_at":"2026-01-05T23:43:10.609805-08:00","close_reason":"Closed","dependencies":[{"issue_id":"workflow-klf","depends_on_id":"workflow-ov5","type":"blocks","created_at":"2026-01-05T23:39:49.805611-08:00","created_by":"pranaygp"},{"issue_id":"workflow-klf","depends_on_id":"workflow-66v","type":"blocks","created_at":"2026-01-05T23:39:49.83923-08:00","created_by":"pranaygp"}]}
{"id":"workflow-nld","title":"Add specVersion to run_created event","description":"Add specVersion to RunCreatedEventDataSchema in /packages/world/src/events.ts","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-05T23:39:39.115906-08:00","created_by":"pranaygp","updated_at":"2026-01-05T23:41:19.844114-08:00","closed_at":"2026-01-05T23:41:19.844114-08:00","close_reason":"Closed","dependencies":[{"issue_id":"workflow-nld","depends_on_id":"workflow-ov5","type":"blocks","created_at":"2026-01-05T23:39:49.542533-08:00","created_by":"pranaygp"}]}
{"id":"workflow-ot2","title":"Update world-postgres to set specVersion","description":"Set specVersion property in world-postgres implementation","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-05T23:39:39.553648-08:00","created_by":"pranaygp","updated_at":"2026-01-05T23:43:10.610968-08:00","closed_at":"2026-01-05T23:43:10.610968-08:00","close_reason":"Closed","dependencies":[{"issue_id":"workflow-ot2","depends_on_id":"workflow-ov5","type":"blocks","created_at":"2026-01-05T23:39:49.965084-08:00","created_by":"pranaygp"},{"issue_id":"workflow-ot2","depends_on_id":"workflow-66v","type":"blocks","created_at":"2026-01-05T23:39:49.999031-08:00","created_by":"pranaygp"}]}
{"id":"workflow-ov5","title":"Add specVersion property to World interface","description":"Add readonly specVersion: string to World interface in /packages/world/src/interfaces.ts","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-05T23:39:38.707284-08:00","created_by":"pranaygp","updated_at":"2026-01-05T23:40:57.592337-08:00","closed_at":"2026-01-05T23:40:57.592337-08:00","close_reason":"Closed"}
{"id":"workflow-qm0","title":"DurableAgent E2E Tests \u0026 Feature Parity with AI SDK ToolLoopAgent","description":"Ensure DurableAgent has full feature compatibility with AI SDK's ToolLoopAgent and is comprehensively tested and documented.\n\n## Goal\nDurableAgent should match the test coverage and feature parity of ToolLoopAgent/streamText from the AI SDK, with comprehensive E2E tests that exercise the full integration (not mocking streamTextIterator).\n\n## Background\nCurrently DurableAgent tests mock `streamTextIterator`, which means we're not testing the actual iteration logic, message threading, or providerMetadata flow. The AI SDK has extensive tests (~19k lines in stream-text.test.ts) that we should mirror for DurableAgent.\n\n## Scope\n\n### Phase 1: Foundation (workflow-qm0.1)\nPort test utilities from AI SDK to enable real integration testing:\n- MockLanguageModel for simulating model responses\n- Stream helpers for creating test streams\n- ID generators for predictable test IDs\n\n### Phase 2: Core E2E Tests (workflow-qm0.2, .3, .4)\nTest the core multi-step tool calling flow:\n- Multi-step iteration (tool → tool → text)\n- Parallel tool execution\n- providerMetadata preservation (critical for Gemini)\n\n### Phase 3: Features \u0026 Callbacks (workflow-qm0.5, .6, .7)\nTest all DurableAgent features:\n- Abort signal handling\n- Callbacks (onStepFinish, onError, onFinish)\n- prepareStep dynamic configuration\n\n### Phase 4: Extended Content (workflow-qm0.8, .9, .10)\nTest advanced features:\n- UIMessageStream output verification\n- Reasoning, sources, files handling\n- Stream transforms (experimental_transform)\n\n### Phase 5: Polish (workflow-qm0.11, .12)\nComplete the package:\n- Comprehensive documentation\n- TypeScript type tests\n\n## Execution Plan\n\n### Parallelization\nAfter workflow-qm0.1 completes, tasks can run in parallel:\n- Group A (P1-P2): workflow-qm0.2, .3, .4, .5, .6, .7 (can all run in parallel)\n- Group B (P3): workflow-qm0.8, .9, .10, .12 (can all run in parallel)\n- Documentation (workflow-qm0.11) waits for Group A core tests\n\n### Estimated Total Effort\n- Phase 1: ~2 hours\n- Phase 2: ~6 hours\n- Phase 3: ~5.5 hours\n- Phase 4: ~6 hours\n- Phase 5: ~5 hours\n- **Total: ~24.5 hours**\n\n### Test File Organization\nAll E2E tests go in: `packages/ai/src/agent/durable-agent.e2e.test.ts`\nType tests go in: `packages/ai/src/agent/durable-agent.test-d.ts`\nTest utilities go in: `packages/ai/src/test/`\n\n## Success Criteria\n- [ ] All E2E tests pass without mocking streamTextIterator\n- [ ] providerMetadata flow fully tested (Gemini thoughtSignature scenario)\n- [ ] Feature parity with AI SDK streamText documented\n- [ ] No regressions in existing tests\n- [ ] Documentation complete with examples\n\n## Related\n- PR #733: Fix for providerMetadata preservation\n- AI SDK reference: `/packages/ai/src/generate-text/stream-text.test.ts`","status":"open","priority":2,"issue_type":"epic","created_at":"2026-01-06T23:28:03.070603-08:00","created_by":"pranaygp","updated_at":"2026-01-06T23:47:38.244216-08:00","labels":["ai","documentation","testing"]}
{"id":"workflow-qm0.1","title":"Port AI SDK test utilities to @workflow/ai","description":"Port essential test utilities from AI SDK to enable real integration testing without mocking streamTextIterator.\n\n## Overview\nThe current DurableAgent tests mock `streamTextIterator`, which means we are not testing the actual iteration logic. To write real E2E tests, we need mock utilities that can simulate model responses at the `LanguageModelV2`/`LanguageModelV3` level.\n\n## Utilities to Port\n\n### Required (High Priority)\n1. **`MockLanguageModelV3`** - Full model mock with `doStream`/`doGenerate`\n   - Source: `/packages/ai/src/test/mock-language-model-v3.ts` in AI SDK\n   - Allows configuring responses per call (tool calls, text, errors)\n   - Must support `providerMetadata` on stream parts\n\n2. **`convertArrayToReadableStream`** - Convert arrays to ReadableStream\n   - Source: `@ai-sdk/provider-utils/test`\n   - Essential for creating mock streams from arrays of chunks\n\n3. **`convertAsyncIterableToArray`** - Stream consumption helper\n   - Source: `@ai-sdk/provider-utils/test`\n   - Useful for collecting stream output in tests\n\n### Optional (Lower Priority)\n4. **`mockId({ prefix: 'id' })`** - Predictable ID generation\n5. **`mockValues(v1, v2, v3)`** - Sequential mock value returns\n6. **`MockTracer`** - Telemetry verification (only if testing telemetry)\n\n## Implementation Notes\n\n### File Location\nCreate test utilities in: `packages/ai/src/test/` directory\n\n### Compatibility\n- Must work with both AI SDK v5 (LanguageModelV2) and v6 (LanguageModelV3)\n- DurableAgent uses `CompatibleLanguageModel` type that supports both\n\n### Key Mock Model Features\n```typescript\n// Example usage pattern\nconst model = createMockModel({\n  responses: [\n    // First call: return tool call\n    {\n      stream: [\n        { type: 'tool-call', toolCallId: '1', toolName: 'search', input: '{}' },\n        { type: 'finish', finishReason: 'tool-calls' },\n      ],\n    },\n    // Second call: return text\n    {\n      stream: [\n        { type: 'text-delta', delta: 'Result' },\n        { type: 'finish', finishReason: 'stop' },\n      ],\n    },\n  ],\n});\n```\n\n## Acceptance Criteria\n- [ ] `MockLanguageModel` class created that implements `CompatibleLanguageModel`\n- [ ] `doStream` returns configurable `ReadableStream\u003cLanguageModelV2StreamPart\u003e`\n- [ ] Can configure multiple responses for sequential calls\n- [ ] `convertArrayToReadableStream` helper available\n- [ ] `convertAsyncIterableToArray` helper available\n- [ ] All utilities exported from `packages/ai/src/test/index.ts`\n- [ ] Basic smoke test verifying mock model works with `doStreamStep`\n\n## Files to Create\n- `packages/ai/src/test/mock-language-model.ts`\n- `packages/ai/src/test/stream-helpers.ts`\n- `packages/ai/src/test/index.ts`","status":"open","priority":2,"issue_type":"task","estimated_minutes":120,"created_at":"2026-01-06T23:28:11.736999-08:00","created_by":"pranaygp","updated_at":"2026-01-06T23:43:22.779269-08:00","labels":["ai","testing"],"dependencies":[{"issue_id":"workflow-qm0.1","depends_on_id":"workflow-qm0","type":"parent-child","created_at":"2026-01-06T23:28:11.737493-08:00","created_by":"pranaygp"}]}
{"id":"workflow-qm0.10","title":"Add E2E tests for experimental_transform","description":"Test stream transformation pipeline (experimental_transform) in DurableAgent.\n\n## Overview\nDurableAgent supports `experimental_transform` which allows inserting TransformStreams into the model response pipeline. This enables use cases like:\n- Filtering/modifying chunks\n- Injecting additional content\n- Early stream termination\n- Logging/debugging\n\n## Test File\nAdd to: `packages/ai/src/agent/durable-agent.e2e.test.ts`\n\n## Test Scenarios\n\n### 1. Single Transform Applied\n```typescript\nit('should apply single transform to stream', async () =\u003e {\n  const transform: StreamTextTransform\u003cToolSet\u003e = () =\u003e {\n    return new TransformStream({\n      transform(chunk, controller) {\n        // Add prefix to text deltas\n        if (chunk.type === 'text-delta') {\n          controller.enqueue({\n            ...chunk,\n            delta: `[MODIFIED] ${chunk.delta}`,\n          });\n        } else {\n          controller.enqueue(chunk);\n        }\n      },\n    });\n  };\n\n  const result = await agent.stream({\n    messages,\n    writable,\n    experimental_transform: transform,\n  });\n\n  expect(result.steps[0].text).toContain('[MODIFIED]');\n});\n```\n\n### 2. Multiple Transforms Chained\n```typescript\nit('should chain multiple transforms in order', async () =\u003e {\n  const transforms: StreamTextTransform\u003cToolSet\u003e[] = [\n    () =\u003e new TransformStream({\n      transform(chunk, controller) {\n        if (chunk.type === 'text-delta') {\n          controller.enqueue({ ...chunk, delta: `[A]${chunk.delta}` });\n        } else {\n          controller.enqueue(chunk);\n        }\n      },\n    }),\n    () =\u003e new TransformStream({\n      transform(chunk, controller) {\n        if (chunk.type === 'text-delta') {\n          controller.enqueue({ ...chunk, delta: `[B]${chunk.delta}` });\n        } else {\n          controller.enqueue(chunk);\n        }\n      },\n    }),\n  ];\n\n  const result = await agent.stream({\n    messages,\n    writable,\n    experimental_transform: transforms,\n  });\n\n  // Order: [B][A]original (B wraps A's output)\n  expect(result.steps[0].text).toContain('[B][A]');\n});\n```\n\n### 3. Transform That Stops Stream\n```typescript\nit('should stop stream when transform calls stopStream', async () =\u003e {\n  const transform: StreamTextTransform\u003cToolSet\u003e = ({ stopStream }) =\u003e {\n    let chunkCount = 0;\n    return new TransformStream({\n      transform(chunk, controller) {\n        chunkCount++;\n        if (chunkCount \u003e 2) {\n          stopStream();\n          return; // Don't enqueue more chunks\n        }\n        controller.enqueue(chunk);\n      },\n    });\n  };\n\n  // Model returns many chunks, but transform stops after 2\n  const result = await agent.stream({\n    messages,\n    writable,\n    experimental_transform: transform,\n  });\n\n  // Verify stream terminated early\n});\n```\n\n### 4. Transform That Modifies Chunks\n```typescript\nit('should allow transform to modify chunk content', async () =\u003e {\n  const transform: StreamTextTransform\u003cToolSet\u003e = () =\u003e {\n    return new TransformStream({\n      transform(chunk, controller) {\n        if (chunk.type === 'tool-call') {\n          // Redact tool input for logging\n          controller.enqueue({\n            ...chunk,\n            input: '[REDACTED]',\n          });\n        } else {\n          controller.enqueue(chunk);\n        }\n      },\n    });\n  };\n\n  // Verify modified chunks in output\n});\n```\n\n### 5. Transform Error Handling\n```typescript\nit('should handle transform errors gracefully', async () =\u003e {\n  const transform: StreamTextTransform\u003cToolSet\u003e = () =\u003e {\n    return new TransformStream({\n      transform(chunk, controller) {\n        if (chunk.type === 'text-delta') {\n          throw new Error('Transform error');\n        }\n        controller.enqueue(chunk);\n      },\n    });\n  };\n\n  // Verify error is propagated/handled appropriately\n  await expect(agent.stream({\n    messages,\n    writable,\n    experimental_transform: transform,\n  })).rejects.toThrow('Transform error');\n});\n```\n\n### 6. Transform Receives Tools Context\n```typescript\nit('should provide tools to transform factory', async () =\u003e {\n  let receivedTools: ToolSet | undefined;\n  \n  const transform: StreamTextTransform\u003cToolSet\u003e = ({ tools }) =\u003e {\n    receivedTools = tools;\n    return new TransformStream();\n  };\n\n  await agent.stream({\n    messages,\n    writable,\n    experimental_transform: transform,\n  });\n\n  // Note: Due to serialization boundaries, tools may be empty inside step\n  // Verify the expected behavior\n});\n```\n\n### 7. Transform Filter by Chunk Type\n```typescript\nit('should allow filtering out specific chunk types', async () =\u003e {\n  const chunks: UIMessageChunk[] = [];\n  const writable = new WritableStream({ write(chunk) { chunks.push(chunk); } });\n\n  const transform: StreamTextTransform\u003cToolSet\u003e = () =\u003e {\n    return new TransformStream({\n      transform(chunk, controller) {\n        // Filter out reasoning chunks\n        if (!chunk.type.startsWith('reasoning-')) {\n          controller.enqueue(chunk);\n        }\n      },\n    });\n  };\n\n  await agent.stream({\n    messages,\n    writable,\n    experimental_transform: transform,\n  });\n\n  expect(chunks.filter(c =\u003e c.type.startsWith('reasoning-')).length).toBe(0);\n});\n```\n\n## Acceptance Criteria\n- [ ] Single transform applied correctly\n- [ ] Multiple transforms compose in correct order\n- [ ] stopStream terminates iteration\n- [ ] Chunk modification works\n- [ ] Transform errors propagate appropriately\n- [ ] Transform factory receives context (tools, stopStream)\n- [ ] Filtering chunks works\n\n## Notes\n- Transforms are applied inside the step boundary (after model.doStream)\n- Due to serialization, tools object may be limited inside transforms\n- stopStream should cleanly terminate without errors\n\n## Dependencies\n- Requires: `workflow-qm0.1` (test utilities)","status":"open","priority":3,"issue_type":"task","estimated_minutes":90,"created_at":"2026-01-06T23:29:16.441622-08:00","created_by":"pranaygp","updated_at":"2026-01-06T23:46:33.244324-08:00","labels":["ai","testing"],"dependencies":[{"issue_id":"workflow-qm0.10","depends_on_id":"workflow-qm0","type":"parent-child","created_at":"2026-01-06T23:29:16.442107-08:00","created_by":"pranaygp"},{"issue_id":"workflow-qm0.10","depends_on_id":"workflow-qm0.1","type":"blocks","created_at":"2026-01-06T23:29:16.443053-08:00","created_by":"pranaygp"}]}
{"id":"workflow-qm0.11","title":"Document DurableAgent API and feature parity with AI SDK","description":"Create comprehensive documentation for DurableAgent API and feature parity with AI SDK.\n\n## Overview\nDurableAgent needs clear documentation explaining:\n1. What it is and why it exists (durability for AI agents)\n2. How to use it\n3. How it compares to AI SDK's streamText/ToolLoopAgent\n4. Migration path from AI SDK\n\n## Documentation Location\nCreate or update: `docs/content/docs/ai/durable-agent.mdx`\n\n## Documentation Sections\n\n### 1. Overview and Purpose\n- What is DurableAgent?\n- Why use it over plain AI SDK streamText?\n- Key benefit: Durability across workflow step boundaries\n- When to use DurableAgent vs regular streamText\n\n### 2. Quick Start\n```typescript\nimport { DurableAgent } from '@workflow/ai';\nimport { z } from 'zod';\n\nconst agent = new DurableAgent({\n  model: 'gpt-4o',\n  tools: {\n    search: {\n      description: 'Search the web',\n      inputSchema: z.object({ query: z.string() }),\n      execute: async ({ query }) =\u003e {\n        // Tool implementation\n        return { results: ['Result 1', 'Result 2'] };\n      },\n    },\n  },\n});\n\nexport default workflow(async (request) =\u003e {\n  const result = await agent.stream({\n    messages: [{ role: 'user', content: 'Search for AI news' }],\n    writable: getUIWritable(),\n  });\n  \n  return result.steps;\n});\n```\n\n### 3. API Reference\n\n#### Constructor Options\n| Option | Type | Description |\n|--------|------|-------------|\n| model | string \\| () =\u003e LanguageModel | Model identifier or factory |\n| tools | ToolSet | Tool definitions |\n| temperature | number | Generation temperature |\n| maxOutputTokens | number | Max tokens per response |\n| ... | ... | ... |\n\n#### stream() Options\n| Option | Type | Description |\n|--------|------|-------------|\n| messages | Message[] | Conversation history |\n| writable | WritableStream | UI message stream |\n| maxSteps | number | Maximum iteration steps |\n| prepareStep | PrepareStepCallback | Per-step configuration |\n| onStepFinish | Callback | Called after each step |\n| onFinish | Callback | Called on completion |\n| onError | Callback | Called on errors |\n| ... | ... | ... |\n\n### 4. Feature Comparison with AI SDK\n\n| Feature | AI SDK streamText | DurableAgent | Notes |\n|---------|------------------|--------------|-------|\n| Multi-step tool calling | ✅ | ✅ | Same behavior |\n| Parallel tool execution | ✅ | ✅ | Same behavior |\n| prepareStep callback | ✅ | ✅ | Same API |\n| onStepFinish callback | ✅ | ✅ | Same API |\n| Durability | ❌ | ✅ | Key differentiator |\n| FatalError handling | ❌ | ✅ | Workflow-specific |\n| ... | ... | ... | ... |\n\n### 5. Examples\n\n#### Basic Tool Calling\n```typescript\n// Show complete working example\n```\n\n#### Multi-Step Conversations\n```typescript\n// Show tool → tool → text flow\n```\n\n#### Custom prepareStep\n```typescript\n// Show dynamic model switching, message injection\n```\n\n#### Error Handling with FatalError\n```typescript\n// Show how FatalError converts to error result\n// vs regular errors that cause retry\n```\n\n#### Abort Handling\n```typescript\n// Show AbortController usage\n```\n\n### 6. Integration with Workflow Durability\n- How DurableAgent leverages 'use step' boundaries\n- What gets persisted between steps\n- Recovery from crashes mid-conversation\n- Serialization considerations (providerMetadata, etc.)\n\n### 7. Migration Guide from AI SDK\n```typescript\n// Before (AI SDK)\nimport { streamText } from 'ai';\nconst result = await streamText({ model, tools, messages });\n\n// After (DurableAgent in workflow)\nimport { DurableAgent } from '@workflow/ai';\nconst agent = new DurableAgent({ model, tools });\nconst result = await agent.stream({ messages, writable });\n```\n\nKey differences:\n- Writable stream required (for UI updates)\n- Model can be string (uses gateway)\n- FatalError for unrecoverable tool errors\n- Runs inside workflow context\n\n## Acceptance Criteria\n- [ ] Overview clearly explains durability benefit\n- [ ] Quick start example works copy-paste\n- [ ] API reference complete with all options\n- [ ] Feature comparison table accurate\n- [ ] All major features have examples\n- [ ] Durability integration explained\n- [ ] Migration guide covers common patterns\n\n## Dependencies\n- Should wait for E2E tests to ensure documented behavior is accurate\n- Requires: `workflow-qm0.2`, `workflow-qm0.3`, `workflow-qm0.4`","status":"open","priority":2,"issue_type":"task","estimated_minutes":240,"created_at":"2026-01-06T23:29:26.030771-08:00","created_by":"pranaygp","updated_at":"2026-01-06T23:46:57.335555-08:00","labels":["ai","documentation"],"dependencies":[{"issue_id":"workflow-qm0.11","depends_on_id":"workflow-qm0","type":"parent-child","created_at":"2026-01-06T23:29:26.031268-08:00","created_by":"pranaygp"},{"issue_id":"workflow-qm0.11","depends_on_id":"workflow-qm0.2","type":"blocks","created_at":"2026-01-06T23:29:26.032208-08:00","created_by":"pranaygp"},{"issue_id":"workflow-qm0.11","depends_on_id":"workflow-qm0.3","type":"blocks","created_at":"2026-01-06T23:29:26.032856-08:00","created_by":"pranaygp"},{"issue_id":"workflow-qm0.11","depends_on_id":"workflow-qm0.4","type":"blocks","created_at":"2026-01-06T23:29:26.033447-08:00","created_by":"pranaygp"}]}
{"id":"workflow-qm0.12","title":"Add TypeScript type tests for DurableAgent","description":"Add TypeScript type tests for DurableAgent using .test-d.ts pattern.\n\n## Overview\nType tests ensure TypeScript correctly infers types for:\n- Tool input/output based on schema\n- Callback parameters\n- Return types\n- Generic constraints\n\nThis catches type regressions at compile time.\n\n## Reference\nAI SDK pattern: `/packages/ai/src/agent/tool-loop-agent.test-d.ts`\n\n## Test File\nCreate: `packages/ai/src/agent/durable-agent.test-d.ts`\n\n## Test Scenarios\n\n### 1. Tool Input Type Inference\n```typescript\nimport { DurableAgent } from './durable-agent';\nimport { z } from 'zod';\nimport { expectTypeOf } from 'vitest';\n\nconst agent = new DurableAgent({\n  model: 'gpt-4',\n  tools: {\n    search: {\n      description: 'Search',\n      inputSchema: z.object({\n        query: z.string(),\n        limit: z.number().optional(),\n      }),\n      execute: async (input) =\u003e {\n        // input should be typed as { query: string; limit?: number }\n        expectTypeOf(input).toEqualTypeOf\u003c{ query: string; limit?: number }\u003e();\n        return { results: [] };\n      },\n    },\n  },\n});\n```\n\n### 2. Tool Output Type Inference\n```typescript\nconst agent = new DurableAgent({\n  model: 'gpt-4',\n  tools: {\n    getData: {\n      description: 'Get data',\n      inputSchema: z.object({}),\n      execute: async () =\u003e {\n        return { data: 'test', count: 42 };\n      },\n    },\n  },\n});\n\n// Tool result type should be inferred\n```\n\n### 3. ToolSet Type Constraints\n```typescript\n// Should error if tool is missing required fields\nconst invalidAgent = new DurableAgent({\n  model: 'gpt-4',\n  tools: {\n    // @ts-expect-error - missing description\n    incomplete: {\n      inputSchema: z.object({}),\n      execute: async () =\u003e ({}),\n    },\n  },\n});\n```\n\n### 4. StreamOptions Type Checking\n```typescript\n// Valid options\nagent.stream({\n  messages: [{ role: 'user', content: 'test' }],\n  writable: new WritableStream(),\n  maxSteps: 10,\n  temperature: 0.7,\n});\n\n// @ts-expect-error - invalid option type\nagent.stream({\n  messages: [{ role: 'user', content: 'test' }],\n  writable: new WritableStream(),\n  maxSteps: 'ten', // Should be number\n});\n```\n\n### 5. Callback Parameter Types\n```typescript\nagent.stream({\n  messages,\n  writable,\n  onStepFinish: (step) =\u003e {\n    expectTypeOf(step.text).toBeString();\n    expectTypeOf(step.toolCalls).toBeArray();\n    expectTypeOf(step.finishReason).toMatchTypeOf\u003cFinishReason\u003e();\n  },\n  onFinish: ({ steps, messages }) =\u003e {\n    expectTypeOf(steps).toBeArray();\n    expectTypeOf(messages).toBeArray();\n  },\n  onError: ({ error }) =\u003e {\n    expectTypeOf(error).toBeUnknown();\n  },\n});\n```\n\n### 6. Return Type Inference\n```typescript\nconst result = await agent.stream({ messages, writable });\n\nexpectTypeOf(result.steps).toBeArray();\nexpectTypeOf(result.messages).toMatchTypeOf\u003cLanguageModelV2Prompt\u003e();\n```\n\n### 7. PrepareStep Callback Types\n```typescript\nagent.stream({\n  messages,\n  writable,\n  prepareStep: ({ stepNumber, steps, messages, experimental_context }) =\u003e {\n    expectTypeOf(stepNumber).toBeNumber();\n    expectTypeOf(steps).toBeArray();\n    \n    return {\n      system: 'New system prompt',\n      temperature: 0.5,\n      // Should allow all valid return fields\n    };\n  },\n});\n```\n\n### 8. Generic Tool Types\n```typescript\n// When using with generics, types should flow through\nfunction createAgent\u003cT extends ToolSet\u003e(tools: T) {\n  return new DurableAgent({ model: 'gpt-4', tools });\n}\n\nconst typedAgent = createAgent({\n  myTool: {\n    description: 'My tool',\n    inputSchema: z.object({ x: z.number() }),\n    execute: async ({ x }) =\u003e ({ doubled: x * 2 }),\n  },\n});\n```\n\n## Acceptance Criteria\n- [ ] Tool input types correctly inferred from zod schema\n- [ ] Tool output types correctly inferred\n- [ ] Invalid tool definitions produce type errors\n- [ ] Stream options are type-checked\n- [ ] Callback parameters have correct types\n- [ ] Return type has correct shape\n- [ ] prepareStep callback types are correct\n- [ ] Generic usage preserves types\n\n## Notes\n- Use `vitest` `expectTypeOf` for type assertions\n- Use `@ts-expect-error` for negative tests\n- Test file must have `.test-d.ts` extension\n\n## Dependencies\n- Requires: `workflow-qm0.1` (for ToolSet types reference)","status":"open","priority":3,"issue_type":"task","estimated_minutes":60,"created_at":"2026-01-06T23:29:33.144652-08:00","created_by":"pranaygp","updated_at":"2026-01-06T23:47:17.940011-08:00","labels":["ai","testing","typescript"],"dependencies":[{"issue_id":"workflow-qm0.12","depends_on_id":"workflow-qm0","type":"parent-child","created_at":"2026-01-06T23:29:33.145128-08:00","created_by":"pranaygp"},{"issue_id":"workflow-qm0.12","depends_on_id":"workflow-qm0.1","type":"blocks","created_at":"2026-01-06T23:29:33.146144-08:00","created_by":"pranaygp"}]}
{"id":"workflow-qm0.2","title":"Add E2E tests for multi-step tool call iteration","description":"Add real integration tests for multi-step tool calling that exercise the full DurableAgent → streamTextIterator → doStreamStep flow.\n\n## Overview\nThis is the core test suite that verifies DurableAgent correctly handles multi-turn conversations with tool calls. Unlike current tests that mock `streamTextIterator`, these tests use a mock model and verify the actual iteration logic.\n\n## Test File\nCreate: `packages/ai/src/agent/durable-agent.e2e.test.ts`\n\n## Test Scenarios\n\n### 1. Single Tool Call → Text Response\n```typescript\nit('should handle single tool call followed by text response', async () =\u003e {\n  // Model returns: tool-call → (tool result provided) → text\n  // Verify: 2 steps, first with tool call, second with text\n});\n```\n\n### 2. Multiple Sequential Tool Call Rounds\n```typescript\nit('should handle multiple rounds of tool calls', async () =\u003e {\n  // Model returns: tool-call → tool-call → text\n  // Verify: 3 steps, conversation history grows correctly\n});\n```\n\n### 3. Chained Tool Calls (Tool Triggers Another Tool)\n```typescript\nit('should handle tool results that trigger more tool calls', async () =\u003e {\n  // First tool returns data, model decides to call second tool\n  // Verify: correct message threading\n});\n```\n\n### 4. maxSteps Limiting Iterations\n```typescript\nit('should stop at maxSteps even if model wants more tools', async () =\u003e {\n  // Model keeps returning tool calls\n  // maxSteps: 3\n  // Verify: stops after 3 steps, no infinite loop\n});\n```\n\n### 5. stopConditions Evaluation\n```typescript\nit('should stop when custom stopCondition is met', async () =\u003e {\n  // stopConditions: [({ steps }) =\u003e steps.length \u003e= 2]\n  // Verify: stops when condition returns true\n});\n```\n\n### 6. Tool Results in Conversation History\n```typescript\nit('should include tool results in subsequent prompts', async () =\u003e {\n  // Verify the model receives:\n  // - user message\n  // - assistant message with tool-call\n  // - tool message with tool-result\n  // - (next model call sees all of this)\n});\n```\n\n## Test Pattern\n```typescript\nimport { createMockModel, convertArrayToReadableStream } from '../test';\n\ndescribe('DurableAgent E2E - Multi-step Tool Calls', () =\u003e {\n  it('should handle tool call iteration', async () =\u003e {\n    let callCount = 0;\n    const model = createMockModel({\n      doStream: async ({ prompt }) =\u003e {\n        callCount++;\n        if (callCount === 1) {\n          return {\n            stream: convertArrayToReadableStream([\n              { type: 'tool-call', toolCallId: '1', toolName: 'search', input: '{\"q\":\"test\"}' },\n              { type: 'finish', finishReason: 'tool-calls' },\n            ]),\n          };\n        }\n        return {\n          stream: convertArrayToReadableStream([\n            { type: 'text-delta', delta: 'Found results' },\n            { type: 'finish', finishReason: 'stop' },\n          ]),\n        };\n      },\n    });\n\n    const agent = new DurableAgent({ model: async () =\u003e model, tools });\n    const result = await agent.stream({ messages, writable });\n    \n    expect(result.steps).toHaveLength(2);\n    expect(result.steps[0].toolCalls).toHaveLength(1);\n    expect(result.steps[1].text).toBe('Found results');\n  });\n});\n```\n\n## Acceptance Criteria\n- [ ] All 6 test scenarios implemented\n- [ ] Tests do NOT mock `streamTextIterator`\n- [ ] Tests verify conversation history is built correctly\n- [ ] Tests verify step results contain expected data\n- [ ] Tests verify tool execution order\n- [ ] maxSteps and stopConditions tested\n\n## Dependencies\n- Requires: `workflow-qm0.1` (test utilities)","status":"open","priority":2,"issue_type":"task","estimated_minutes":180,"created_at":"2026-01-06T23:28:20.164892-08:00","created_by":"pranaygp","updated_at":"2026-01-06T23:43:43.464544-08:00","labels":["ai","testing"],"dependencies":[{"issue_id":"workflow-qm0.2","depends_on_id":"workflow-qm0","type":"parent-child","created_at":"2026-01-06T23:28:20.165354-08:00","created_by":"pranaygp"},{"issue_id":"workflow-qm0.2","depends_on_id":"workflow-qm0.1","type":"blocks","created_at":"2026-01-06T23:28:20.166211-08:00","created_by":"pranaygp"}]}
{"id":"workflow-qm0.3","title":"Add E2E tests for parallel tool execution","description":"Test parallel tool call handling in DurableAgent when the model returns multiple tool calls in a single response.\n\n## Overview\nWhen a model returns multiple tool calls in one response (e.g., \"get weather for NYC and London\"), DurableAgent should execute all tools concurrently and collect results.\n\n## Test File\nAdd to: `packages/ai/src/agent/durable-agent.e2e.test.ts`\n\n## Test Scenarios\n\n### 1. Multiple Tool Calls in Single Response\n```typescript\nit('should execute multiple tool calls from single response', async () =\u003e {\n  // Model returns two tool calls at once\n  const model = createMockModel({\n    doStream: async () =\u003e ({\n      stream: convertArrayToReadableStream([\n        { type: 'tool-call', toolCallId: '1', toolName: 'weather', input: '{\"city\":\"NYC\"}' },\n        { type: 'tool-call', toolCallId: '2', toolName: 'weather', input: '{\"city\":\"London\"}' },\n        { type: 'finish', finishReason: 'tool-calls' },\n      ]),\n    }),\n  });\n  \n  // Verify both tools were called\n  // Verify both results sent back to model\n});\n```\n\n### 2. Concurrent Execution Verification\n```typescript\nit('should execute tools concurrently not sequentially', async () =\u003e {\n  const executionTimes: number[] = [];\n  const tools = {\n    slowTool: {\n      execute: async () =\u003e {\n        executionTimes.push(Date.now());\n        await sleep(50);\n        return { done: true };\n      },\n    },\n  };\n  \n  // Two tool calls, each takes 50ms\n  // If sequential: ~100ms total\n  // If parallel: ~50ms total\n  // Verify execution overlaps\n});\n```\n\n### 3. Results Correctly Associated with Tool Call IDs\n```typescript\nit('should match tool results to correct tool call IDs', async () =\u003e {\n  // Verify toolResult.toolCallId matches original toolCall.toolCallId\n  // Important for model to understand which result goes with which call\n});\n```\n\n### 4. Order Independence\n```typescript\nit('should handle tool results completing in any order', async () =\u003e {\n  // Tool 1 takes 100ms, Tool 2 takes 10ms\n  // Tool 2 completes first\n  // Verify both results collected correctly\n});\n```\n\n### 5. Mixed Success/Failure in Parallel\n```typescript\nit('should handle some tools succeeding and some failing', async () =\u003e {\n  // Tool 1 succeeds, Tool 2 throws FatalError\n  // Verify Tool 1 result is success\n  // Verify Tool 2 result is error-text\n  // Verify iteration continues (FatalError is converted, not thrown)\n});\n```\n\n## Acceptance Criteria\n- [ ] Multiple parallel tool calls executed\n- [ ] Execution timing shows concurrency (not sequential)\n- [ ] Tool results correctly associated with tool call IDs\n- [ ] Order independence verified\n- [ ] Mixed success/failure handled correctly\n- [ ] All results passed back to model in tool message\n\n## Notes\n- DurableAgent uses `Promise.allSettled` pattern for parallel execution\n- FatalError in tools is converted to error result, not thrown\n- Non-FatalError is re-thrown (causes step retry)\n\n## Dependencies\n- Requires: `workflow-qm0.1` (test utilities)","status":"open","priority":2,"issue_type":"task","estimated_minutes":90,"created_at":"2026-01-06T23:28:26.78689-08:00","created_by":"pranaygp","updated_at":"2026-01-06T23:43:59.815062-08:00","labels":["ai","testing"],"dependencies":[{"issue_id":"workflow-qm0.3","depends_on_id":"workflow-qm0","type":"parent-child","created_at":"2026-01-06T23:28:26.787334-08:00","created_by":"pranaygp"},{"issue_id":"workflow-qm0.3","depends_on_id":"workflow-qm0.1","type":"blocks","created_at":"2026-01-06T23:28:26.788202-08:00","created_by":"pranaygp"}]}
{"id":"workflow-qm0.4","title":"Add E2E tests for providerMetadata/providerOptions flow","description":"Comprehensive E2E tests for providerMetadata preservation across the full DurableAgent flow. This is critical for providers like Gemini that require thoughtSignature on tool calls.\n\n## Overview\nThe AI SDK returns `providerMetadata` on tool calls (e.g., `{ google: { thoughtSignature: \"...\" } }`). This metadata must be:\n1. Captured from the model response\n2. Mapped to `providerOptions` when adding tool calls to conversation history\n3. Sent back to the provider on subsequent calls\n\nWithout this, Gemini thinking models fail with: \"function call is missing a thought_signature\"\n\n## Related PR\nThis test suite validates the fix implemented in PR #733.\n\n## Test File\nAdd to: `packages/ai/src/agent/durable-agent.e2e.test.ts`\n\n## Test Scenarios\n\n### 1. providerMetadata on Tool Calls → providerOptions in Prompt\n```typescript\nit('should preserve providerMetadata as providerOptions in conversation history', async () =\u003e {\n  let secondCallPrompt: LanguageModelV2Prompt | undefined;\n  \n  const model = createMockModel({\n    doStream: async ({ prompt }) =\u003e {\n      if (!secondCallPrompt \u0026\u0026 prompt.length \u003e 1) {\n        secondCallPrompt = prompt;\n      }\n      // First call: return tool call with providerMetadata\n      return {\n        stream: convertArrayToReadableStream([\n          {\n            type: 'tool-call',\n            toolCallId: '1',\n            toolName: 'search',\n            input: '{}',\n            providerMetadata: {\n              google: { thoughtSignature: 'sig_abc123' },\n            },\n          },\n          { type: 'finish', finishReason: 'tool-calls' },\n        ]),\n      };\n    },\n  });\n\n  // After iteration, verify secondCallPrompt contains:\n  // assistant message with tool-call part having providerOptions.google.thoughtSignature\n});\n```\n\n### 2. Gemini thoughtSignature Multi-Turn Scenario\n```typescript\nit('should handle Gemini thoughtSignature through multi-turn conversation', async () =\u003e {\n  // Simulate realistic Gemini flow:\n  // Turn 1: Model returns tool call with thoughtSignature\n  // Turn 1: Tool executes (success or error)\n  // Turn 2: Model receives prompt with thoughtSignature preserved\n  // Turn 2: Model returns text response\n  \n  // This is the exact scenario that was failing before PR #733\n});\n```\n\n### 3. providerMetadata on Finish Chunk\n```typescript\nit('should capture providerMetadata from finish chunk in step result', async () =\u003e {\n  const model = createMockModel({\n    doStream: async () =\u003e ({\n      stream: convertArrayToReadableStream([\n        { type: 'text-delta', delta: 'Hello' },\n        {\n          type: 'finish',\n          finishReason: 'stop',\n          providerMetadata: { anthropic: { stopReason: 'end_turn' } },\n        },\n      ]),\n    }),\n  });\n\n  const result = await agent.stream({ messages, writable });\n  expect(result.steps[0].providerMetadata).toEqual({\n    anthropic: { stopReason: 'end_turn' },\n  });\n});\n```\n\n### 4. Mixed Tool Calls With/Without Metadata\n```typescript\nit('should handle tool calls with and without providerMetadata', async () =\u003e {\n  // Tool call 1: has providerMetadata\n  // Tool call 2: no providerMetadata\n  // Verify: first has providerOptions, second does not\n});\n```\n\n### 5. Metadata Through Multiple Steps\n```typescript\nit('should preserve different metadata through multiple tool call steps', async () =\u003e {\n  // Step 1: tool call with metadata A\n  // Step 2: tool call with metadata B\n  // Verify: each step's metadata is preserved independently\n});\n```\n\n### 6. Serialization Compatibility\n```typescript\nit('should serialize providerMetadata correctly across step boundaries', async () =\u003e {\n  // Verify providerMetadata (plain JSON object) survives\n  // the workflow serialization layer (devalue)\n  // This is important for workflow durability\n});\n```\n\n## Acceptance Criteria\n- [ ] providerMetadata → providerOptions mapping verified E2E\n- [ ] Gemini thoughtSignature scenario passes\n- [ ] Finish chunk providerMetadata captured in step result\n- [ ] Mixed metadata/no-metadata tool calls handled\n- [ ] Multi-step metadata preservation verified\n- [ ] Serialization compatibility verified\n\n## Priority\nP1 - This validates the critical fix in PR #733\n\n## Dependencies\n- Requires: `workflow-qm0.1` (test utilities)","status":"open","priority":1,"issue_type":"task","estimated_minutes":120,"created_at":"2026-01-06T23:28:33.678143-08:00","created_by":"pranaygp","updated_at":"2026-01-06T23:44:21.233108-08:00","labels":["ai","testing"],"dependencies":[{"issue_id":"workflow-qm0.4","depends_on_id":"workflow-qm0","type":"parent-child","created_at":"2026-01-06T23:28:33.678604-08:00","created_by":"pranaygp"},{"issue_id":"workflow-qm0.4","depends_on_id":"workflow-qm0.1","type":"blocks","created_at":"2026-01-06T23:28:33.679489-08:00","created_by":"pranaygp"}]}
{"id":"workflow-qm0.5","title":"Add E2E tests for abort signal handling","description":"Test abort signal handling during DurableAgent stream iteration to ensure proper cleanup and callback invocation.\n\n## Overview\nDurableAgent accepts an `abortSignal` in generation settings. When aborted, the agent should:\n1. Stop iteration gracefully\n2. Invoke `onAbort` callback\n3. Clean up resources (close streams, etc.)\n\n## Test File\nAdd to: `packages/ai/src/agent/durable-agent.e2e.test.ts`\n\n## Test Scenarios\n\n### 1. Abort Before Stream Starts\n```typescript\nit('should handle abort signal that is already aborted', async () =\u003e {\n  const controller = new AbortController();\n  controller.abort(); // Already aborted\n  \n  const agent = new DurableAgent({ model, tools });\n  const onAbort = vi.fn();\n  \n  await agent.stream({\n    messages,\n    writable,\n    abortSignal: controller.signal,\n    onAbort,\n  });\n  \n  expect(onAbort).toHaveBeenCalled();\n  // Verify no model calls made\n});\n```\n\n### 2. Abort Mid-Stream (During Text Generation)\n```typescript\nit('should stop stream when aborted during text generation', async () =\u003e {\n  const controller = new AbortController();\n  let chunkCount = 0;\n  \n  const model = createMockModel({\n    doStream: async () =\u003e ({\n      stream: convertArrayToReadableStream([\n        { type: 'text-delta', delta: 'Hello ' },\n        { type: 'text-delta', delta: 'World' }, // Abort after this\n        { type: 'text-delta', delta: ' More text' }, // Should not be processed\n        { type: 'finish', finishReason: 'stop' },\n      ]),\n    }),\n  });\n\n  // Abort after 2 chunks\n  // Verify partial text received\n  // Verify stream closed cleanly\n});\n```\n\n### 3. Abort During Tool Execution\n```typescript\nit('should handle abort during tool execution', async () =\u003e {\n  const controller = new AbortController();\n  \n  const tools = {\n    slowTool: {\n      execute: async (input, { abortSignal }) =\u003e {\n        // Tool should receive abort signal\n        await sleep(100);\n        if (abortSignal?.aborted) {\n          throw new Error('Aborted');\n        }\n        return { result: 'done' };\n      },\n    },\n  };\n\n  // Start stream, abort while tool is executing\n  // Verify tool received abort signal\n});\n```\n\n### 4. Abort Between Steps\n```typescript\nit('should stop iteration when aborted between steps', async () =\u003e {\n  const controller = new AbortController();\n  let stepCount = 0;\n  \n  const onStepFinish = vi.fn(() =\u003e {\n    stepCount++;\n    if (stepCount === 1) {\n      controller.abort(); // Abort after first step\n    }\n  });\n\n  // Model would return multiple tool calls\n  // Verify only 1 step completed\n  // Verify onAbort called\n});\n```\n\n### 5. onAbort Callback Invocation\n```typescript\nit('should call onAbort callback with correct arguments', async () =\u003e {\n  const onAbort = vi.fn();\n  const controller = new AbortController();\n  \n  // Abort mid-stream\n  controller.abort();\n  \n  await agent.stream({ messages, writable, onAbort, abortSignal: controller.signal });\n  \n  expect(onAbort).toHaveBeenCalledTimes(1);\n  // Verify onAbort receives relevant context\n});\n```\n\n### 6. Cleanup Verification\n```typescript\nit('should close writable stream on abort', async () =\u003e {\n  const controller = new AbortController();\n  const writableChunks: UIMessageChunk[] = [];\n  const writable = new WritableStream({\n    write(chunk) { writableChunks.push(chunk); },\n    close() { /* should be called */ },\n    abort(reason) { /* may be called */ },\n  });\n\n  // Verify stream properly closed/aborted\n});\n```\n\n## Edge Cases\n- Abort signal with custom reason\n- Multiple abort calls (idempotent)\n- Abort after iteration already complete (no-op)\n\n## Acceptance Criteria\n- [ ] Pre-aborted signal handled\n- [ ] Mid-stream abort stops processing\n- [ ] Abort during tool execution passes signal to tool\n- [ ] Abort between steps stops iteration\n- [ ] onAbort callback invoked with correct timing\n- [ ] Writable stream properly closed\n\n## Dependencies\n- Requires: `workflow-qm0.1` (test utilities)","status":"open","priority":2,"issue_type":"task","estimated_minutes":90,"created_at":"2026-01-06T23:28:41.920355-08:00","created_by":"pranaygp","updated_at":"2026-01-06T23:44:40.430423-08:00","labels":["ai","testing"],"dependencies":[{"issue_id":"workflow-qm0.5","depends_on_id":"workflow-qm0","type":"parent-child","created_at":"2026-01-06T23:28:41.920831-08:00","created_by":"pranaygp"},{"issue_id":"workflow-qm0.5","depends_on_id":"workflow-qm0.1","type":"blocks","created_at":"2026-01-06T23:28:41.921698-08:00","created_by":"pranaygp"}]}
{"id":"workflow-qm0.6","title":"Add E2E tests for callbacks (onStepFinish, onError, onFinish)","description":"Test all callback invocations (onStepFinish, onError, onFinish) during DurableAgent execution to verify correct timing and arguments.\n\n## Overview\nDurableAgent provides several callbacks for observing agent execution:\n- `onStepFinish`: Called after each step completes\n- `onError`: Called when errors occur (tool failures, model errors)\n- `onFinish`: Called when entire agent execution completes\n\n## Test File\nAdd to: `packages/ai/src/agent/durable-agent.e2e.test.ts`\n\n## Test Scenarios\n\n### 1. onStepFinish Called After Each Step\n```typescript\nit('should call onStepFinish after each step with correct StepResult', async () =\u003e {\n  const onStepFinish = vi.fn();\n  \n  // Model returns: tool call → text\n  // Expect onStepFinish called twice\n  \n  await agent.stream({ messages, writable, onStepFinish });\n  \n  expect(onStepFinish).toHaveBeenCalledTimes(2);\n  \n  // First call: tool call step\n  expect(onStepFinish.mock.calls[0][0]).toMatchObject({\n    finishReason: 'tool-calls',\n    toolCalls: [{ toolName: 'search' }],\n  });\n  \n  // Second call: text step\n  expect(onStepFinish.mock.calls[1][0]).toMatchObject({\n    finishReason: 'stop',\n    text: 'Result',\n  });\n});\n```\n\n### 2. StepResult Contains Expected Data\n```typescript\nit('should include all expected fields in StepResult', async () =\u003e {\n  const onStepFinish = vi.fn();\n  \n  await agent.stream({ messages, writable, onStepFinish });\n  \n  const stepResult = onStepFinish.mock.calls[0][0];\n  \n  // Verify all StepResult fields\n  expect(stepResult).toHaveProperty('text');\n  expect(stepResult).toHaveProperty('toolCalls');\n  expect(stepResult).toHaveProperty('toolResults');\n  expect(stepResult).toHaveProperty('finishReason');\n  expect(stepResult).toHaveProperty('usage');\n  expect(stepResult).toHaveProperty('content');\n  expect(stepResult).toHaveProperty('reasoning');\n  expect(stepResult).toHaveProperty('sources');\n  expect(stepResult).toHaveProperty('files');\n  expect(stepResult).toHaveProperty('providerMetadata');\n});\n```\n\n### 3. onError Called on Tool Failure (FatalError)\n```typescript\nit('should call onError when tool throws FatalError', async () =\u003e {\n  const onError = vi.fn();\n  \n  const tools = {\n    failingTool: {\n      execute: async () =\u003e {\n        throw new FatalError('Tool failed');\n      },\n    },\n  };\n\n  await agent.stream({ messages, writable, onError });\n  \n  // FatalError is converted to error result, not thrown\n  // But onError should still be called\n  expect(onError).toHaveBeenCalledWith({ error: expect.any(FatalError) });\n});\n```\n\n### 4. onError Called on Model Error\n```typescript\nit('should call onError when model throws', async () =\u003e {\n  const onError = vi.fn();\n  \n  const model = createMockModel({\n    doStream: async () =\u003e {\n      throw new Error('Model API error');\n    },\n  });\n\n  await expect(agent.stream({ messages, writable, onError }))\n    .rejects.toThrow('Model API error');\n  \n  expect(onError).toHaveBeenCalledWith({ error: expect.any(Error) });\n});\n```\n\n### 5. onFinish Called with Final State\n```typescript\nit('should call onFinish with all steps and messages', async () =\u003e {\n  const onFinish = vi.fn();\n  \n  // Multi-step execution\n  await agent.stream({ messages, writable, onFinish });\n  \n  expect(onFinish).toHaveBeenCalledTimes(1);\n  expect(onFinish).toHaveBeenCalledWith({\n    steps: expect.arrayContaining([\n      expect.objectContaining({ finishReason: 'tool-calls' }),\n      expect.objectContaining({ finishReason: 'stop' }),\n    ]),\n    messages: expect.any(Array),\n  });\n});\n```\n\n### 6. Callback Order Verification\n```typescript\nit('should call callbacks in correct order', async () =\u003e {\n  const callOrder: string[] = [];\n  \n  const onStepFinish = vi.fn(() =\u003e callOrder.push('step'));\n  const onFinish = vi.fn(() =\u003e callOrder.push('finish'));\n  \n  await agent.stream({ messages, writable, onStepFinish, onFinish });\n  \n  // Steps complete before finish\n  expect(callOrder).toEqual(['step', 'step', 'finish']);\n});\n```\n\n### 7. Async Callbacks\n```typescript\nit('should await async callbacks', async () =\u003e {\n  let stepFinishCompleted = false;\n  \n  const onStepFinish = vi.fn(async () =\u003e {\n    await sleep(50);\n    stepFinishCompleted = true;\n  });\n  \n  const onFinish = vi.fn(() =\u003e {\n    expect(stepFinishCompleted).toBe(true); // Should be true\n  });\n\n  await agent.stream({ messages, writable, onStepFinish, onFinish });\n});\n```\n\n## Acceptance Criteria\n- [ ] onStepFinish called after each step\n- [ ] StepResult contains all expected fields\n- [ ] onError called on FatalError (tool failure)\n- [ ] onError called on model errors\n- [ ] onFinish called with steps and messages\n- [ ] Callback order is correct (steps → finish)\n- [ ] Async callbacks are properly awaited\n\n## Dependencies\n- Requires: `workflow-qm0.1` (test utilities)","status":"open","priority":2,"issue_type":"task","estimated_minutes":120,"created_at":"2026-01-06T23:28:48.595264-08:00","created_by":"pranaygp","updated_at":"2026-01-06T23:45:02.669964-08:00","labels":["ai","testing"],"dependencies":[{"issue_id":"workflow-qm0.6","depends_on_id":"workflow-qm0","type":"parent-child","created_at":"2026-01-06T23:28:48.595739-08:00","created_by":"pranaygp"},{"issue_id":"workflow-qm0.6","depends_on_id":"workflow-qm0.1","type":"blocks","created_at":"2026-01-06T23:28:48.596643-08:00","created_by":"pranaygp"}]}
{"id":"workflow-qm0.7","title":"Add E2E tests for prepareStep callback","description":"Test prepareStep callback for dynamic per-step configuration in DurableAgent.\n\n## Overview\nThe `prepareStep` callback is called before each model call, allowing dynamic configuration of:\n- System prompt\n- Model selection\n- Messages\n- Generation settings (temperature, maxTokens, etc.)\n- Tool choice\n- Active tools\n- Experimental context\n\nThis enables sophisticated patterns like model routing, dynamic prompting, and tool filtering.\n\n## Test File\nAdd to: `packages/ai/src/agent/durable-agent.e2e.test.ts`\n\n## Test Scenarios\n\n### 1. Modify System Prompt Per Step\n```typescript\nit('should allow prepareStep to modify system prompt', async () =\u003e {\n  let capturedPrompts: string[] = [];\n  \n  const model = createMockModel({\n    doStream: async ({ prompt }) =\u003e {\n      const systemMsg = prompt.find(m =\u003e m.role === 'system');\n      capturedPrompts.push(systemMsg?.content || ');\n      return { stream: /* ... */ };\n    },\n  });\n\n  const prepareStep = vi.fn(({ stepNumber }) =\u003e ({\n    system: `Step ${stepNumber} system prompt`,\n  }));\n\n  await agent.stream({ messages, writable, prepareStep });\n  \n  expect(capturedPrompts[0]).toBe('Step 0 system prompt');\n  expect(capturedPrompts[1]).toBe('Step 1 system prompt');\n});\n```\n\n### 2. Switch Model Mid-Conversation\n```typescript\nit('should allow prepareStep to switch models', async () =\u003e {\n  const model1 = createMockModel({ /* fast model */ });\n  const model2 = createMockModel({ /* powerful model */ });\n  \n  const prepareStep = vi.fn(({ stepNumber }) =\u003e ({\n    model: stepNumber === 0 ? model1 : model2,\n  }));\n\n  // Verify different models used for different steps\n});\n```\n\n### 3. Modify Messages Before Step\n```typescript\nit('should allow prepareStep to inject messages', async () =\u003e {\n  let capturedMessages: any[];\n  \n  const prepareStep = vi.fn(({ messages }) =\u003e ({\n    messages: [\n      ...messages,\n      { role: 'user', content: [{ type: 'text', text: 'Injected reminder' }] },\n    ],\n  }));\n\n  // Verify injected message appears in prompt\n});\n```\n\n### 4. Update experimental_context\n```typescript\nit('should allow prepareStep to update context', async () =\u003e {\n  let toolReceivedContext: any;\n  \n  const tools = {\n    contextTool: {\n      execute: async (input, { experimental_context }) =\u003e {\n        toolReceivedContext = experimental_context;\n        return {};\n      },\n    },\n  };\n\n  const prepareStep = vi.fn(({ stepNumber }) =\u003e ({\n    experimental_context: { stepNumber, customData: 'test' },\n  }));\n\n  // Verify tool receives updated context\n});\n```\n\n### 5. Filter activeTools Per Step\n```typescript\nit('should allow prepareStep to filter available tools', async () =\u003e {\n  const tools = {\n    searchTool: { execute: async () =\u003e ({ found: true }) },\n    writeTool: { execute: async () =\u003e ({ written: true }) },\n  };\n\n  const prepareStep = vi.fn(({ stepNumber }) =\u003e ({\n    activeTools: stepNumber === 0 ? ['searchTool'] : ['writeTool'],\n  }));\n\n  // Step 0: only searchTool available\n  // Step 1: only writeTool available\n});\n```\n\n### 6. Override Generation Settings\n```typescript\nit('should allow prepareStep to override generation settings', async () =\u003e {\n  let capturedSettings: any[] = [];\n  \n  const model = createMockModel({\n    doStream: async (options) =\u003e {\n      capturedSettings.push({\n        temperature: options.temperature,\n        maxOutputTokens: options.maxOutputTokens,\n      });\n      return { stream: /* ... */ };\n    },\n  });\n\n  const prepareStep = vi.fn(({ stepNumber }) =\u003e ({\n    temperature: stepNumber === 0 ? 0.1 : 0.9,\n    maxOutputTokens: stepNumber === 0 ? 100 : 1000,\n  }));\n\n  // Verify settings change per step\n});\n```\n\n### 7. Modify toolChoice Per Step\n```typescript\nit('should allow prepareStep to modify toolChoice', async () =\u003e {\n  const prepareStep = vi.fn(({ stepNumber }) =\u003e ({\n    toolChoice: stepNumber === 0 ? 'required' : 'auto',\n  }));\n\n  // Step 0: force tool use\n  // Step 1: auto (model decides)\n});\n```\n\n### 8. Access Step Information\n```typescript\nit('should provide step information to prepareStep', async () =\u003e {\n  const prepareStep = vi.fn();\n  \n  await agent.stream({ messages, writable, prepareStep });\n  \n  // Verify prepareStep received:\n  expect(prepareStep).toHaveBeenCalledWith({\n    model: expect.anything(),\n    stepNumber: 0,\n    steps: [],\n    messages: expect.any(Array),\n    experimental_context: undefined,\n  });\n  \n  // Second call has previous step\n  expect(prepareStep.mock.calls[1][0].steps).toHaveLength(1);\n});\n```\n\n## Acceptance Criteria\n- [ ] System prompt modification works\n- [ ] Model switching works\n- [ ] Message injection works\n- [ ] Context update works and tool receives it\n- [ ] activeTools filtering works\n- [ ] Generation settings override works\n- [ ] toolChoice modification works\n- [ ] prepareStep receives correct step information\n\n## Dependencies\n- Requires: `workflow-qm0.1` (test utilities)","status":"open","priority":2,"issue_type":"task","estimated_minutes":120,"created_at":"2026-01-06T23:28:57.349296-08:00","created_by":"pranaygp","updated_at":"2026-01-06T23:45:23.987282-08:00","labels":["ai","testing"],"dependencies":[{"issue_id":"workflow-qm0.7","depends_on_id":"workflow-qm0","type":"parent-child","created_at":"2026-01-06T23:28:57.349751-08:00","created_by":"pranaygp"},{"issue_id":"workflow-qm0.7","depends_on_id":"workflow-qm0.1","type":"blocks","created_at":"2026-01-06T23:28:57.350638-08:00","created_by":"pranaygp"}]}
{"id":"workflow-qm0.8","title":"Add E2E tests for UIMessageStream output","description":"Test that UIMessageChunks are correctly written to the writable stream during DurableAgent execution.\n\n## Overview\nDurableAgent writes `UIMessageChunk` objects to the provided `WritableStream`. This is how the UI receives real-time updates. We need to verify all chunk types are emitted correctly.\n\n## Test File\nAdd to: `packages/ai/src/agent/durable-agent.e2e.test.ts`\n\n## UIMessageChunk Types to Test\n\n### Text Chunks\n```typescript\n{ type: 'text-start', id: string, providerMetadata?: object }\n{ type: 'text-delta', id: string, delta: string, providerMetadata?: object }\n{ type: 'text-end', id: string, providerMetadata?: object }\n```\n\n### Reasoning Chunks\n```typescript\n{ type: 'reasoning-start', id: string, providerMetadata?: object }\n{ type: 'reasoning-delta', id: string, delta: string, providerMetadata?: object }\n{ type: 'reasoning-end', id: string, providerMetadata?: object }\n```\n\n### Tool Chunks\n```typescript\n{ type: 'tool-input-start', toolCallId: string, toolName: string, providerExecuted?: boolean }\n{ type: 'tool-input-delta', toolCallId: string, inputTextDelta: string }\n{ type: 'tool-input-available', toolCallId: string, toolName: string, input: object, providerMetadata?: object }\n{ type: 'tool-output-available', toolCallId: string, output: string }\n```\n\n### Other Chunks\n```typescript\n{ type: 'file', mediaType: string, url: string }\n{ type: 'source-url', sourceId: string, url: string, title?: string }\n{ type: 'source-document', sourceId: string, mediaType: string, title?: string, filename?: string }\n{ type: 'error', errorText: string }\n{ type: 'start' }\n{ type: 'start-step' }\n{ type: 'finish-step' }\n```\n\n## Test Scenarios\n\n### 1. Text Streaming Chunks\n```typescript\nit('should emit text-start, text-delta, text-end chunks', async () =\u003e {\n  const chunks: UIMessageChunk[] = [];\n  const writable = new WritableStream({ write(chunk) { chunks.push(chunk); } });\n\n  // Model returns text deltas\n  await agent.stream({ messages, writable });\n\n  const textChunks = chunks.filter(c =\u003e c.type.startsWith('text-'));\n  expect(textChunks[0]).toMatchObject({ type: 'text-start' });\n  expect(textChunks[1]).toMatchObject({ type: 'text-delta', delta: 'Hello' });\n  expect(textChunks[textChunks.length - 1]).toMatchObject({ type: 'text-end' });\n});\n```\n\n### 2. Tool Input/Output Chunks\n```typescript\nit('should emit tool chunks in correct order', async () =\u003e {\n  const chunks: UIMessageChunk[] = [];\n  // ...\n\n  const toolChunks = chunks.filter(c =\u003e c.type.startsWith('tool-'));\n  \n  // Order: input-start → input-delta(s) → input-available → output-available\n  expect(toolChunks.map(c =\u003e c.type)).toEqual([\n    'tool-input-start',\n    'tool-input-delta',\n    'tool-input-available',\n    'tool-output-available',\n  ]);\n});\n```\n\n### 3. Reasoning Chunks\n```typescript\nit('should emit reasoning chunks for thinking models', async () =\u003e {\n  // Model returns reasoning parts\n  const chunks: UIMessageChunk[] = [];\n  \n  const reasoningChunks = chunks.filter(c =\u003e c.type.startsWith('reasoning-'));\n  expect(reasoningChunks).toHaveLength(3); // start, delta, end\n});\n```\n\n### 4. Step Boundary Chunks\n```typescript\nit('should emit start-step and finish-step for each step', async () =\u003e {\n  const chunks: UIMessageChunk[] = [];\n  \n  // Multi-step execution\n  await agent.stream({ messages, writable });\n\n  const stepChunks = chunks.filter(c =\u003e \n    c.type === 'start-step' || c.type === 'finish-step'\n  );\n  \n  // 2 steps = 4 chunks (start-step, finish-step, start-step, finish-step)\n  expect(stepChunks.map(c =\u003e c.type)).toEqual([\n    'start-step', 'finish-step',\n    'start-step', 'finish-step',\n  ]);\n});\n```\n\n### 5. Error Chunks\n```typescript\nit('should emit error chunk on model error', async () =\u003e {\n  const model = createMockModel({\n    doStream: async () =\u003e ({\n      stream: convertArrayToReadableStream([\n        { type: 'error', error: new Error('Model failed') },\n      ]),\n    }),\n  });\n\n  const chunks: UIMessageChunk[] = [];\n  await agent.stream({ messages, writable });\n  \n  expect(chunks).toContainEqual({\n    type: 'error',\n    errorText: 'Model failed',\n  });\n});\n```\n\n### 6. File Chunks\n```typescript\nit('should emit file chunks with correct URL', async () =\u003e {\n  // Model returns file part\n  const chunks: UIMessageChunk[] = [];\n  \n  const fileChunk = chunks.find(c =\u003e c.type === 'file');\n  expect(fileChunk).toMatchObject({\n    type: 'file',\n    mediaType: 'image/png',\n    url: expect.stringMatching(/^data:image\\/png;base64,/),\n  });\n});\n```\n\n### 7. Source Chunks\n```typescript\nit('should emit source-url and source-document chunks', async () =\u003e {\n  // Model returns source parts\n  const chunks: UIMessageChunk[] = [];\n  \n  expect(chunks).toContainEqual({\n    type: 'source-url',\n    sourceId: expect.any(String),\n    url: 'https://example.com',\n    title: 'Example',\n  });\n});\n```\n\n## Acceptance Criteria\n- [ ] All text chunk types emitted correctly\n- [ ] All tool chunk types emitted in correct order\n- [ ] Reasoning chunks emitted for thinking models\n- [ ] Step boundary chunks (start-step, finish-step) emitted\n- [ ] Error chunks emitted with readable error text\n- [ ] File chunks include proper data URLs\n- [ ] Source chunks include all metadata\n\n## Notes\n- Chunk order is important for UI rendering\n- providerMetadata on chunks should be preserved\n- The `start` chunk is only emitted once (first step)\n\n## Dependencies\n- Requires: `workflow-qm0.1` (test utilities)","status":"open","priority":3,"issue_type":"task","estimated_minutes":180,"created_at":"2026-01-06T23:29:04.339195-08:00","created_by":"pranaygp","updated_at":"2026-01-06T23:45:47.888926-08:00","labels":["ai","testing"],"dependencies":[{"issue_id":"workflow-qm0.8","depends_on_id":"workflow-qm0","type":"parent-child","created_at":"2026-01-06T23:29:04.339659-08:00","created_by":"pranaygp"},{"issue_id":"workflow-qm0.8","depends_on_id":"workflow-qm0.1","type":"blocks","created_at":"2026-01-06T23:29:04.34055-08:00","created_by":"pranaygp"}]}
{"id":"workflow-qm0.9","title":"Add E2E tests for reasoning, sources, and files","description":"Test handling of extended content types (reasoning, sources, files) in DurableAgent responses.\n\n## Overview\nModern AI models can return more than just text. This task tests that DurableAgent correctly captures and exposes:\n- Reasoning content (thinking/chain-of-thought from models like Claude, Gemini, o1)\n- Source citations (URL and document references)\n- Generated files (images, audio, etc.)\n\n## Test File\nAdd to: `packages/ai/src/agent/durable-agent.e2e.test.ts`\n\n## Test Scenarios\n\n### 1. Reasoning Content (Thinking Models)\n```typescript\nit('should capture reasoning content in step result', async () =\u003e {\n  const model = createMockModel({\n    doStream: async () =\u003e ({\n      stream: convertArrayToReadableStream([\n        { type: 'reasoning-start', id: 'r1' },\n        { type: 'reasoning-delta', id: 'r1', delta: 'Let me think...' },\n        { type: 'reasoning-delta', id: 'r1', delta: ' I should search first.' },\n        { type: 'reasoning-end', id: 'r1' },\n        { type: 'text-delta', delta: 'Here is my answer' },\n        { type: 'finish', finishReason: 'stop' },\n      ]),\n    }),\n  });\n\n  const result = await agent.stream({ messages, writable });\n  \n  expect(result.steps[0].reasoning).toHaveLength(1);\n  expect(result.steps[0].reasoningText).toBe('Let me think... I should search first.');\n});\n```\n\n### 2. URL Sources\n```typescript\nit('should capture URL sources in step result', async () =\u003e {\n  const model = createMockModel({\n    doStream: async () =\u003e ({\n      stream: convertArrayToReadableStream([\n        {\n          type: 'source',\n          sourceType: 'url',\n          id: 's1',\n          url: 'https://example.com/article',\n          title: 'Example Article',\n        },\n        { type: 'text-delta', delta: 'According to the article...' },\n        { type: 'finish', finishReason: 'stop' },\n      ]),\n    }),\n  });\n\n  const result = await agent.stream({ messages, writable });\n  \n  expect(result.steps[0].sources).toContainEqual({\n    sourceType: 'url',\n    id: 's1',\n    url: 'https://example.com/article',\n    title: 'Example Article',\n  });\n});\n```\n\n### 3. Document Sources\n```typescript\nit('should capture document sources in step result', async () =\u003e {\n  const model = createMockModel({\n    doStream: async () =\u003e ({\n      stream: convertArrayToReadableStream([\n        {\n          type: 'source',\n          sourceType: 'document',\n          id: 'd1',\n          mediaType: 'application/pdf',\n          title: 'Report Q4',\n          filename: 'report-q4.pdf',\n        },\n        { type: 'text-delta', delta: 'The report shows...' },\n        { type: 'finish', finishReason: 'stop' },\n      ]),\n    }),\n  });\n\n  const result = await agent.stream({ messages, writable });\n  \n  expect(result.steps[0].sources).toContainEqual({\n    sourceType: 'document',\n    id: 'd1',\n    mediaType: 'application/pdf',\n    title: 'Report Q4',\n    filename: 'report-q4.pdf',\n  });\n});\n```\n\n### 4. Generated Files (Images)\n```typescript\nit('should capture generated files in step result', async () =\u003e {\n  const imageData = new Uint8Array([137, 80, 78, 71]); // PNG header\n  \n  const model = createMockModel({\n    doStream: async () =\u003e ({\n      stream: convertArrayToReadableStream([\n        {\n          type: 'file',\n          mediaType: 'image/png',\n          data: imageData,\n        },\n        { type: 'text-delta', delta: 'Here is the generated image' },\n        { type: 'finish', finishReason: 'stop' },\n      ]),\n    }),\n  });\n\n  const result = await agent.stream({ messages, writable });\n  \n  expect(result.steps[0].files).toHaveLength(1);\n  expect(result.steps[0].files[0]).toMatchObject({\n    mediaType: 'image/png',\n    base64: expect.any(String),\n    uint8Array: expect.any(Uint8Array),\n  });\n});\n```\n\n### 5. Mixed Content Types\n```typescript\nit('should handle mixed content types in single response', async () =\u003e {\n  const model = createMockModel({\n    doStream: async () =\u003e ({\n      stream: convertArrayToReadableStream([\n        { type: 'reasoning-start', id: 'r1' },\n        { type: 'reasoning-delta', id: 'r1', delta: 'Thinking...' },\n        { type: 'reasoning-end', id: 'r1' },\n        { type: 'source', sourceType: 'url', id: 's1', url: 'https://example.com' },\n        { type: 'file', mediaType: 'image/png', data: new Uint8Array([1,2,3]) },\n        { type: 'text-delta', delta: 'Final answer' },\n        { type: 'finish', finishReason: 'stop' },\n      ]),\n    }),\n  });\n\n  const result = await agent.stream({ messages, writable });\n  \n  expect(result.steps[0].reasoning).toHaveLength(1);\n  expect(result.steps[0].sources).toHaveLength(1);\n  expect(result.steps[0].files).toHaveLength(1);\n  expect(result.steps[0].text).toBe('Final answer');\n});\n```\n\n### 6. providerMetadata on Extended Content\n```typescript\nit('should preserve providerMetadata on reasoning parts', async () =\u003e {\n  const model = createMockModel({\n    doStream: async () =\u003e ({\n      stream: convertArrayToReadableStream([\n        {\n          type: 'reasoning-start',\n          id: 'r1',\n          providerMetadata: { anthropic: { thinking: true } },\n        },\n        // ...\n      ]),\n    }),\n  });\n\n  // Verify providerMetadata captured\n});\n```\n\n## Acceptance Criteria\n- [ ] Reasoning text aggregated and captured in step result\n- [ ] URL sources captured with all metadata\n- [ ] Document sources captured with all metadata\n- [ ] Generated files converted to base64 and uint8Array\n- [ ] Mixed content types handled in same response\n- [ ] providerMetadata preserved on extended content\n\n## Notes\n- Files require conversion from Uint8Array to base64 for storage\n- Reasoning may span multiple delta chunks\n- Sources and files can appear alongside text\n\n## Dependencies\n- Requires: `workflow-qm0.1` (test utilities)","status":"open","priority":3,"issue_type":"task","estimated_minutes":90,"created_at":"2026-01-06T23:29:10.087116-08:00","created_by":"pranaygp","updated_at":"2026-01-06T23:46:10.746979-08:00","labels":["ai","testing"],"dependencies":[{"issue_id":"workflow-qm0.9","depends_on_id":"workflow-qm0","type":"parent-child","created_at":"2026-01-06T23:29:10.087629-08:00","created_by":"pranaygp"},{"issue_id":"workflow-qm0.9","depends_on_id":"workflow-qm0.1","type":"blocks","created_at":"2026-01-06T23:29:10.088566-08:00","created_by":"pranaygp"}]}
{"id":"workflow-t1f","title":"Update world-testing to set specVersion","description":"Set specVersion property in world-testing implementation","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-05T23:39:39.701813-08:00","created_by":"pranaygp","updated_at":"2026-01-05T23:42:08.00548-08:00","closed_at":"2026-01-05T23:42:08.00548-08:00","close_reason":"world-testing is a test suite helper, not a World implementation - no specVersion needed","dependencies":[{"issue_id":"workflow-t1f","depends_on_id":"workflow-ov5","type":"blocks","created_at":"2026-01-05T23:39:50.125375-08:00","created_by":"pranaygp"},{"issue_id":"workflow-t1f","depends_on_id":"workflow-66v","type":"blocks","created_at":"2026-01-05T23:39:50.159512-08:00","created_by":"pranaygp"}]}
{"id":"workflow-t2t","title":"Update docs-writer agent to run docs tests","description":"Update the docs-writer claude agent to always run docs tests (pnpm test in packages/docs-typecheck or similar) after completing any documentation task to validate the changes.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-05T21:33:21.116101-08:00","created_by":"pranaygp","updated_at":"2026-01-05T21:48:51.110335-08:00","closed_at":"2026-01-05T21:48:51.110335-08:00","close_reason":"Added TypeScript code sample validation (pnpm test:docs) to the docs-writer agent's validation requirements"}
{"id":"workflow-tmc","title":"Run build and typecheck","description":"Verify all changes build and typecheck correctly","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-05T23:39:39.851729-08:00","created_by":"pranaygp","updated_at":"2026-01-05T23:45:06.13741-08:00","closed_at":"2026-01-05T23:45:06.13741-08:00","close_reason":"Closed","dependencies":[{"issue_id":"workflow-tmc","depends_on_id":"workflow-dg3","type":"blocks","created_at":"2026-01-05T23:39:50.290062-08:00","created_by":"pranaygp"},{"issue_id":"workflow-tmc","depends_on_id":"workflow-klf","type":"blocks","created_at":"2026-01-05T23:39:50.323122-08:00","created_by":"pranaygp"},{"issue_id":"workflow-tmc","depends_on_id":"workflow-ot2","type":"blocks","created_at":"2026-01-05T23:39:50.354527-08:00","created_by":"pranaygp"},{"issue_id":"workflow-tmc","depends_on_id":"workflow-t1f","type":"blocks","created_at":"2026-01-05T23:39:50.385126-08:00","created_by":"pranaygp"},{"issue_id":"workflow-tmc","depends_on_id":"workflow-1rq","type":"blocks","created_at":"2026-01-05T23:39:50.417109-08:00","created_by":"pranaygp"},{"issue_id":"workflow-tmc","depends_on_id":"workflow-nld","type":"blocks","created_at":"2026-01-05T23:39:50.448764-08:00","created_by":"pranaygp"}]}
