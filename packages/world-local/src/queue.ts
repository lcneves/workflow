import { setTimeout } from 'node:timers/promises';
import { JsonTransport } from '@vercel/queue';
import { Ansi } from '@workflow/errors';
import {
  MessageId,
  type Queue,
  QueuePrefix,
  ValidQueueName,
} from '@workflow/world';
import { Sema } from 'async-sema';
import chalk from 'chalk';
import { monotonicFactory } from 'ulid';
import { Agent } from 'undici';
import z from 'zod';
import type { Config } from './config.js';
import { resolveBaseUrl } from './config.js';
import { PACKAGE_VERSION } from './init.js';
import * as Logger from './logger.js';

// For local queue, there is no technical limit on the message visibility lifespan,
// but the environment variable can be used for testing purposes to set a max visibility limit.
const LOCAL_QUEUE_MAX_VISIBILITY =
  parseInt(process.env.WORKFLOW_LOCAL_QUEUE_MAX_VISIBILITY ?? '0', 10) ||
  Infinity;

// The local workers share the same Node.js process and event loop,
// so we need to limit concurrency to avoid overwhelming the system.
const DEFAULT_CONCURRENCY_LIMIT = 100;
const WORKFLOW_LOCAL_QUEUE_CONCURRENCY =
  parseInt(process.env.WORKFLOW_LOCAL_QUEUE_CONCURRENCY ?? '0', 10) ||
  DEFAULT_CONCURRENCY_LIMIT;

// Create a custom agent optimized for high-concurrency local workflows:
// - headersTimeout: 0 allows long-running steps
// - connections: 100 allows many parallel connections to the same host
// - pipelining: 1 (default) for HTTP/1.1 compatibility
// - keepAliveTimeout: 30s keeps connections warm for rapid step execution
const httpAgent = new Agent({
  headersTimeout: 0,
  connections: 100,
  keepAliveTimeout: 30_000,
});

export function createQueue(config: Partial<Config>): Queue {
  const transport = new JsonTransport();
  const generateId = monotonicFactory();
  const semaphore = new Sema(WORKFLOW_LOCAL_QUEUE_CONCURRENCY);

  /**
   * holds inflight messages by idempotency key to ensure
   * that we don't queue the same message multiple times
   */
  const inflightMessages = new Map<string, MessageId>();

  const queue: Queue['queue'] = async (queueName, message, opts) => {
    const cleanup = [] as (() => void)[];

    if (opts?.idempotencyKey) {
      const existing = inflightMessages.get(opts.idempotencyKey);
      if (existing) {
        return { messageId: existing };
      }
    }

    const body = transport.serialize(message);
    let pathname: string;
    if (queueName.startsWith('__wkf_step_')) {
      pathname = `step`;
    } else if (queueName.startsWith('__wkf_workflow_')) {
      pathname = `flow`;
    } else {
      throw new Error(
        `Unknown queue name prefix. Valid prefixes are ${QueuePrefix.options.map((x) => x.value).join(', ')}`
      );
    }
    const messageId = MessageId.parse(`msg_${generateId()}`);

    if (opts?.idempotencyKey) {
      const key = opts.idempotencyKey;
      inflightMessages.set(key, messageId);
      cleanup.push(() => {
        inflightMessages.delete(key);
      });
    }

    (async () => {
      const token = semaphore.tryAcquire();
      if (!token) {
        console.warn(
          `[world-local]: concurrency limit (${WORKFLOW_LOCAL_QUEUE_CONCURRENCY}) reached, waiting for queue to free up`
        );
        await semaphore.acquire();
      }
      try {
        let defaultRetriesLeft = 3;
        const baseUrl = await resolveBaseUrl(config);
        for (let attempt = 0; defaultRetriesLeft > 0; attempt++) {
          defaultRetriesLeft--;

          const response = await fetch(
            `${baseUrl}/.well-known/workflow/v1/${pathname}`,
            {
              method: 'POST',
              duplex: 'half',
              dispatcher: httpAgent,
              headers: {
                'content-type': 'application/json',
                'x-vqs-queue-name': queueName,
                'x-vqs-message-id': messageId,
                'x-vqs-message-attempt': String(attempt + 1),
              },
              body,
            }
          );

          if (response.ok) {
            return;
          }

          const text = await response.text();

          if (response.status === 503) {
            try {
              const timeoutSeconds = Number(JSON.parse(text).timeoutSeconds);
              await setTimeout(timeoutSeconds * 1000);
              defaultRetriesLeft++;
              continue;
            } catch {}
          }

          writeFailedExecutionMessage({
            willRetry: defaultRetriesLeft > 0,
            response,
            queueName,
            body,
            responseText: text,
          });
        }

        console.error(
          chalk.red(
            `[local world] ${chalk.bold('fatal:')} Reached max retries of local world queue implementation`
          )
        );
      } finally {
        semaphore.release();
      }
    })()
      .catch((err) => {
        // Silently ignore client disconnect errors (e.g., browser refresh during streaming)
        // These are expected and should not cause unhandled rejection warnings
        const isAbortError =
          err?.name === 'AbortError' || err?.name === 'ResponseAborted';
        if (!isAbortError) {
          console.error('[local world] Queue operation failed:', err);
        }
      })
      .finally(() => {
        for (const fn of cleanup) {
          fn();
        }
      });

    return { messageId };
  };

  const HeaderParser = z
    .object({
      'x-vqs-queue-name': ValidQueueName,
      'x-vqs-message-id': MessageId,
      'x-vqs-message-attempt': z.coerce.number(),
    })
    .transform((data) => ({
      queueName: data['x-vqs-queue-name'],
      messageId: data['x-vqs-message-id'],
      attempt: data['x-vqs-message-attempt'],
    }));

  async function parseRequest(
    req: Request
  ): Promise<
    | [
        headers: z.infer<typeof HeaderParser>,
        bodyStream: ReadableStream<Uint8Array>,
        null,
      ]
    | [null, null, Response]
  > {
    const headers = HeaderParser.safeParse(Object.fromEntries(req.headers));

    if (!headers.success) {
      return [
        null,
        null,
        Response.json(
          {
            error: 'Invalid or missing headers',
            details: z.treeifyError(headers.error),
          },
          { status: 400 }
        ),
      ] as const;
    }

    if (!req.body) {
      return [
        null,
        null,
        Response.json({ error: 'Missing request body' }, { status: 400 }),
      ] as const;
    }

    return [headers.data, req.body, null] as const;
  }

  const createQueueHandler: Queue['createQueueHandler'] = (prefix, handler) => {
    return async (req) => {
      const [headers, bodyStream, parseError] = await parseRequest(req);
      if (parseError) return parseError;
      const { queueName, messageId, attempt } = headers;

      if (!queueName.startsWith(prefix)) {
        return Response.json(
          {
            error: 'Mismatched queue prefix',
            details: {
              requestedQueue: queueName,
              configuredPrefix: prefix,
            },
          },
          { status: 400 }
        );
      }

      const body = await new JsonTransport().deserialize(bodyStream);
      try {
        const result = await handler(body, { attempt, queueName, messageId });

        let timeoutSeconds: number | null = null;
        if (typeof result?.timeoutSeconds === 'number') {
          timeoutSeconds = Math.min(
            result.timeoutSeconds,
            LOCAL_QUEUE_MAX_VISIBILITY
          );
        }

        if (timeoutSeconds) {
          return Response.json({ timeoutSeconds }, { status: 503 });
        }

        return Response.json({ ok: true });
      } catch (error) {
        return new Response(String(error), { status: 500 });
      }
    };
  };

  const getDeploymentId: Queue['getDeploymentId'] = async () => {
    return `dpl_local@${PACKAGE_VERSION}`;
  };

  return { queue, createQueueHandler, getDeploymentId };
}

export function writeFailedExecutionMessage({
  queueName,
  response,
  body,
  responseText,
  willRetry,
}: {
  queueName: string;
  willRetry: boolean;
  response: Response;
  body: Buffer;
  responseText: string;
}) {
  const level = willRetry ? 'warn' : 'error';
  Logger.write(
    level,
    Ansi.frame(
      `${chalk.bold(`${level}:`)} failed to execute ${!willRetry ? '' : chalk.italic(' and will retry')}.`,
      [
        responseText || 'No reason provided.',
        ...(willRetry
          ? []
          : [chalk.italic('This message failed and will not be retried.')]),
        ...(process.env.WORKFLOW_LOCAL_WORLD_DEBUG_REQUEST_ERRORS !== '1'
          ? []
          : [
              chalk.reset(
                [
                  `queue name: ${queueName}`,
                  `response status: ${response.status}`,
                  Ansi.frame(
                    'headers:',
                    Array.from(
                      response.headers,
                      ([key, value]) => `${key}=${value}`
                    )
                  ),
                  Ansi.frame('request body', [body.toString()]),
                ].join('\n')
              ),
            ]),
      ]
    )
  );
}
