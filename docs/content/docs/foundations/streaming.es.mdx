---
title: Transmisión
---

Los flujos de trabajo pueden transmitir datos en tiempo real a los clientes sin esperar a que el flujo de trabajo completo termine. Esto permite entregar actualizaciones de progreso, contenido generado por IA, mensajes de registro y otros datos incrementales mientras los flujos de trabajo se ejecutan.

## Introducción a `getWritable()`

Cada ejecución de flujo de trabajo tiene una secuencia escribible predeterminada a la que los pasos pueden escribir usando [`getWritable()`](/docs/api-reference/workflow/get-writable). Los datos escritos en esta secuencia se ponen inmediatamente a disposición de los clientes que consumen la salida del flujo de trabajo.

```typescript title="workflows/simple-streaming.ts" lineNumbers
import { getWritable } from "workflow";

async function writeProgress(message: string) {
  "use step";

  // Steps can write to the run's default stream
  const writable = getWritable<string>(); // [!code highlight]
  const writer = writable.getWriter();
  await writer.write(message);
  writer.releaseLock();
}

export async function simpleStreamingWorkflow() {
  "use workflow";

  await writeProgress("Starting task...");
  await writeProgress("Processing data...");
  await writeProgress("Task complete!");
}
```

### Consumiendo la secuencia

Usa la propiedad `readable` del objeto `Run` para consumir la secuencia desde tu ruta de la API:

```typescript title="app/api/stream/route.ts" lineNumbers
import { start } from "workflow/api";
import { simpleStreamingWorkflow } from "./workflows/simple";

export async function POST() {
  const run = await start(simpleStreamingWorkflow);

  // Return the readable stream to the client
  return new Response(run.readable, {
    headers: { "Content-Type": "text/plain" }
  });
}
```

Cuando un cliente realiza una solicitud a este endpoint, recibirá cada mensaje a medida que se escribe, sin esperar a que el flujo de trabajo termine.

### Reanudar secuencias desde un punto específico

Usa `run.getReadable({ startIndex })` para reanudar una secuencia desde una posición específica. Esto es útil para reconectarse después de timeouts o interrupciones de red:

```typescript title="app/api/resume-stream/[runId]/route.ts" lineNumbers
import { getRun } from "workflow/api";

export async function GET(
  request: Request,
  { params }: { params: Promise<{ runId: string }> }
) {
  const { runId } = await params;
  const { searchParams } = new URL(request.url);

  // Client provides the last chunk index they received
  const startIndexParam = searchParams.get("startIndex"); // [!code highlight]
  const startIndex = startIndexParam ? parseInt(startIndexParam, 10) : undefined; // [!code highlight]

  const run = getRun(runId);
  const stream = run.getReadable({ startIndex }); // [!code highlight]

  return new Response(stream, {
    headers: { "Content-Type": "text/plain" }
  });
}
```

Esto permite a los clientes reconectarse y continuar recibiendo datos desde donde se quedaron, en lugar de reiniciar desde el principio.

## Las secuencias como tipos de datos

[`ReadableStream`](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream) y [`WritableStream`](https://developer.mozilla.org/en-US/docs/Web/API/WritableStream) son tipos estándar de la Web Streams API que Workflow DevKit hace serializables. Estos no son tipos personalizados: siguen el estándar web, pero Workflow DevKit añade la capacidad de pasarlos entre funciones manteniendo sus capacidades de streaming.

A diferencia de los valores regulares que se serializan completamente en el registro de eventos, las secuencias mantienen sus capacidades de streaming cuando se pasan entre funciones.

**Propiedades clave:**
- Las referencias a secuencias pueden pasarse entre funciones de flujo de trabajo y pasos
- Los datos de la secuencia fluyen directamente sin almacenarse en el registro de eventos
- Las secuencias preservan su estado a través de los puntos de suspensión del flujo de trabajo

<Callout type="info">
**Cómo persisten las secuencias a través de las suspensiones del flujo de trabajo**

Las secuencias en Workflow DevKit están respaldadas por un almacenamiento persistente y reanudable proporcionado por la implementación del "mundo". Esto es lo que permite que las secuencias mantengan su estado incluso cuando los flujos de trabajo se suspenden y reanudan:

- **Despliegues en Vercel**: Las secuencias están respaldadas por un stream basado en Redis de alto rendimiento
- **Desarrollo local**: Los fragmentos de la secuencia se almacenan en el sistema de archivos
</Callout>

### Pasar secuencias como argumentos

Dado que las secuencias son tipos de datos serializables, no necesitas usar el especial [`getWritable()`](/docs/api-reference/workflow/get-writable). Incluso puedes encadenar tus propias secuencias a través de los flujos de trabajo, pasándolas como argumentos desde el exterior hacia los pasos.

Aquí hay un ejemplo de pasar la secuencia del body de una request a través de un flujo de trabajo hacia un paso que la procesa:

```typescript title="app/api/upload/route.ts" lineNumbers
import { start } from "workflow/api";
import { streamProcessingWorkflow } from "./workflows/streaming";

export async function POST(request: Request) {
  // Streams can be passed as workflow arguments
  const run = await start(streamProcessingWorkflow, [request.body]); // [!code highlight]
  await run.result();

  return Response.json({ status: "complete" });
}
```

```typescript title="workflows/streaming.ts" lineNumbers
export async function streamProcessingWorkflow(
  inputStream: ReadableStream<Uint8Array> // [!code highlight]
) {
  "use workflow";

  // Workflow passes stream to step for processing
  const result = await processInputStream(inputStream); // [!code highlight]
  return { length: result.length };
}

async function processInputStream(input: ReadableStream<Uint8Array>) {
  "use step";

  // Step reads from the stream
  const chunks: Uint8Array[] = [];

  for await (const chunk of input) {
    chunks.push(chunk);
  }

  return Buffer.concat(chunks).toString("utf8");
}
```

## Limitación importante

<Callout type="info">
**Las secuencias no pueden usarse directamente en el contexto del flujo de trabajo**

No puedes leer ni escribir en secuencias directamente dentro de una función de flujo de trabajo. Todas las operaciones con secuencias deben ocurrir en funciones de paso.
</Callout>

Las funciones de flujo de trabajo deben ser deterministas para soportar la reejecución (replay). Dado que las secuencias evitan el registro de eventos por motivos de rendimiento, leer datos de una secuencia en un flujo de trabajo rompería la determinismo: cada reejecución podría ver datos diferentes. Al exigir que todas las operaciones con secuencias ocurran en pasos, el framework garantiza un comportamiento consistente.

Para más información sobre determinismo y reejecución, consulta [Flujos de trabajo y pasos](/docs/foundations/workflows-and-steps).

```typescript title="workflows/bad-example.ts" lineNumbers
export async function badWorkflow() {
  "use workflow";

  const writable = getWritable<string>();

  // Cannot read/write streams in workflow context
  const writer = writable.getWriter(); // [!code highlight]
  await writer.write("data"); // [!code highlight]
}
```

```typescript title="workflows/good-example.ts" lineNumbers
export async function goodWorkflow() {
  "use workflow";

  // Delegate stream operations to steps
  await writeToStream("data");
}

async function writeToStream(data: string) {
  "use step";

  // Stream operations must happen in steps
  const writable = getWritable<string>();
  const writer = writable.getWriter();
  await writer.write(data);
  writer.releaseLock();
}
```

## Secuencias con espacio de nombres

Usa `getWritable({ namespace: 'name' })` para crear múltiples secuencias independientes para distintos tipos de datos. Esto es útil cuando quieres separar registros, métricas, salidas de datos u otros canales distintos.

```typescript title="workflows/multi-stream.ts" lineNumbers
import { getWritable } from "workflow";

type LogEntry = { level: string; message: string };
type MetricEntry = { cpu: number; memory: number };

async function writeLogs() {
  "use step";

  const logs = getWritable<LogEntry>({ namespace: "logs" }); // [!code highlight]
  const writer = logs.getWriter();

  await writer.write({ level: "info", message: "Task started" });
  await writer.write({ level: "info", message: "Processing..." });

  writer.releaseLock();
}

async function writeMetrics() {
  "use step";

  const metrics = getWritable<MetricEntry>({ namespace: "metrics" }); // [!code highlight]
  const writer = metrics.getWriter();

  await writer.write({ cpu: 45, memory: 512 });
  await writer.write({ cpu: 52, memory: 520 });

  writer.releaseLock();
}

async function closeStreams() {
  "use step";

  await getWritable({ namespace: "logs" }).close();
  await getWritable({ namespace: "metrics" }).close();
}

export async function multiStreamWorkflow() {
  "use workflow";

  await writeLogs();
  await writeMetrics();
  await closeStreams();
}
```

### Consumiendo secuencias con espacio de nombres

Usa `run.getReadable({ namespace: 'name' })` para acceder a secuencias específicas:

```typescript title="app/api/multi-stream/route.ts" lineNumbers
import { start } from "workflow/api";
import { multiStreamWorkflow } from "./workflows/multi";

type LogEntry = { level: string; message: string };
type MetricEntry = { cpu: number; memory: number };

export async function POST(request: Request) {
  const run = await start(multiStreamWorkflow);

  // Access specific named streams // [!code highlight]
  const logs = run.getReadable<LogEntry>({ namespace: "logs" }); // [!code highlight]
  const metrics = run.getReadable<MetricEntry>({ namespace: "metrics" }); // [!code highlight]

  // Return the logs stream to the client
  return new Response(logs, {
    headers: { "Content-Type": "application/json" }
  });
}
```

## Patrones comunes

### Actualizaciones de progreso para tareas de larga duración

Envía actualizaciones incrementales de progreso para mantener informados a los usuarios durante flujos de trabajo largos:

```typescript title="workflows/batch-processing.ts" lineNumbers
import { getWritable, sleep } from "workflow";

type ProgressUpdate = {
  item: string;
  progress: number;
  status: string;
};

async function processItem(
  item: string,
  current: number,
  total: number
) {
  "use step";

  const writable = getWritable<ProgressUpdate>(); // [!code highlight]
  const writer = writable.getWriter();

  // Simulate processing
  await new Promise(resolve => setTimeout(resolve, 1000));

  // Send progress update // [!code highlight]
  await writer.write({ // [!code highlight]
    item, // [!code highlight]
    progress: Math.round((current / total) * 100), // [!code highlight]
    status: "processing" // [!code highlight]
  }); // [!code highlight]

  writer.releaseLock();
}

async function finalizeProgress() {
  "use step";

  await getWritable().close();
}

export async function batchProcessingWorkflow(items: string[]) {
  "use workflow";

  for (let i = 0; i < items.length; i++) {
    await processItem(items[i], i + 1, items.length);
    await sleep("1s");
  }

  await finalizeProgress();
}
```

### Transmitir respuestas de IA con `DurableAgent`

Transmite contenido generado por IA usando [`DurableAgent`](/docs/api-reference/workflow-ai/durable-agent) de `@workflow/ai`. Las herramientas también pueden emitir actualizaciones de progreso al mismo stream usando [fragmentos de datos](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#streaming-custom-data) con el tipo [`UIMessageChunk`](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol) del SDK de IA:

```typescript title="workflows/ai-assistant.ts" lineNumbers
import { DurableAgent } from "@workflow/ai/agent";
import { getWritable } from "workflow";
import { z } from "zod";
import type { UIMessageChunk } from "ai";

async function searchFlights({ query }: { query: string }) {
  "use step";

  // Tools can emit progress updates to the stream
  const writable = getWritable<UIMessageChunk>(); // [!code highlight]
  const writer = writable.getWriter(); // [!code highlight]
  await writer.write({ // [!code highlight]
    type: "data-progress", // [!code highlight]
    data: { message: `Searching flights for ${query}...` }, // [!code highlight]
    transient: true, // [!code highlight]
  }); // [!code highlight]
  writer.releaseLock(); // [!code highlight]

  // ... search logic ...
  return { flights: [/* results */] };
}

export async function aiAssistantWorkflow(userMessage: string) {
  "use workflow";

  const agent = new DurableAgent({
    model: "anthropic/claude-haiku-4.5",
    system: "You are a helpful flight assistant.",
    tools: {
      searchFlights: {
        description: "Search for flights",
        inputSchema: z.object({ query: z.string() }),
        execute: searchFlights,
      },
    },
  });

  // LLM response will be streamed to the run's writable
  await agent.stream({
    messages: [{ role: "user", content: userMessage }],
    writable: getWritable<UIMessageChunk>(), // [!code highlight]
  });
}
```

```typescript title="app/api/ai-assistant/route.ts" lineNumbers
import { createUIMessageStreamResponse } from "ai";
import { start } from "workflow/api";
import { aiAssistantWorkflow } from "./workflows/ai";

export async function POST(request: Request) {
  const { message } = await request.json();

  const run = await start(aiAssistantWorkflow, [message]);

  return createUIMessageStreamResponse({
    stream: run.readable,
  });
}
```

<Callout type="info">
Para una implementación completa, consulta el [ejemplo de reserva de vuelos](https://github.com/vercel/workflow-examples/tree/main/flight-booking-app) que demuestra la transmisión de respuestas de IA con actualizaciones de progreso de herramientas.
</Callout>

### Transmisión entre pasos

Un paso produce una secuencia y otro paso la consume:

```typescript title="workflows/stream-pipeline.ts" lineNumbers
export async function streamPipelineWorkflow() {
  "use workflow";

  // Streams can be passed between steps
  const stream = await generateData(); // [!code highlight]
  const results = await consumeData(stream); // [!code highlight]

  return { count: results.length };
}

async function generateData(): Promise<ReadableStream<number>> {
  "use step";

  // Producer step creates a stream
  return new ReadableStream<number>({
    start(controller) {
      for (let i = 0; i < 10; i++) {
        controller.enqueue(i);
      }
      controller.close();
    }
  });
}

async function consumeData(readable: ReadableStream<number>) {
  "use step";

  // Consumer step reads from the stream
  const values: number[] = [];
  for await (const value of readable) {
    values.push(value);
  }
  return values;
}
```

### Procesamiento de archivos grandes sin sobrecarga de memoria

Procesa archivos grandes transmitiendo fragmentos a través de pasos de transformación:

```typescript title="workflows/file-processing.ts" lineNumbers
export async function fileProcessingWorkflow(fileUrl: string) {
  "use workflow";

  // Chain streams through multiple processing steps
  const rawStream = await downloadFile(fileUrl); // [!code highlight]
  const processedStream = await transformData(rawStream); // [!code highlight]
  await uploadResult(processedStream); // [!code highlight]
}

async function downloadFile(url: string): Promise<ReadableStream<Uint8Array>> {
  "use step";
  const response = await fetch(url);
  return response.body!;
}

async function transformData(input: ReadableStream<Uint8Array>): Promise<ReadableStream<Uint8Array>> {
  "use step";

  // Transform stream chunks without loading entire file into memory
  return input.pipeThrough(new TransformStream<Uint8Array, Uint8Array>({
    transform(chunk, controller) {
      // Process each chunk individually
      controller.enqueue(chunk);
    }
  }));
}

async function uploadResult(stream: ReadableStream<Uint8Array>) {
  "use step";
  await fetch("https://storage.example.com/upload", {
    method: "POST",
    body: stream,
  });
}
```

## Buenas prácticas

**Liberar los bloqueos correctamente:**

```typescript lineNumbers
const writer = writable.getWriter();
try {
  await writer.write(data);
} finally {
  writer.releaseLock(); // Always release
}
```

<Callout type="info">
Los bloqueos de secuencia adquiridos en un paso solo aplican dentro de ese paso, no a través de otros pasos. Esto permite que varios escritores escriban en la misma secuencia concurrentemente.
</Callout>

<Callout type="info">
Si no se libera un bloqueo, el proceso del paso no puede terminar. Aunque el paso devuelva y el flujo de trabajo continúe, el proceso subyacente permanecerá activo hasta que expire el tiempo de espera.
</Callout>

**Cerrar las secuencias cuando se haya terminado:**

```typescript lineNumbers
async function finalizeStream() {
  "use step";

  await getWritable().close(); // Signal completion
}
```

Las secuencias se cierran automáticamente cuando la ejecución del flujo de trabajo finaliza, pero cerrarlas explícitamente indica la finalización a los consumidores antes.

**Usar secuencias tipadas para seguridad de tipos:**

```typescript lineNumbers
const writable = getWritable<MyDataType>();
const writer = writable.getWriter();
await writer.write({ /* typed data */ });
```

## Errores en las secuencias

Cuando un paso devuelve una secuencia, el paso se considera exitoso una vez que devuelve, incluso si la secuencia más tarde encuentra un error. El flujo de trabajo no volverá a intentar automáticamente el paso. El consumidor de la secuencia debe manejar los errores de forma adecuada. Para más sobre el comportamiento de reintentos, consulta [Errores y reintentos](/docs/foundations/errors-and-retries).

```typescript title="workflows/stream-error-handling.ts" lineNumbers
import { FatalError } from "workflow";

async function produceStream(): Promise<ReadableStream<number>> {
  "use step";

  // Step succeeds once it returns the stream
  return new ReadableStream<number>({
    start(controller) {
      controller.enqueue(1);
      controller.enqueue(2);
      // Error occurs after step has completed // [!code highlight]
      controller.error(new Error("Stream failed")); // [!code highlight]
    }
  });
}

async function consumeStream(stream: ReadableStream<number>) {
  "use step";

  try { // [!code highlight]
    for await (const value of stream) {
      console.log(value);
    }
  } catch (error) { // [!code highlight]
    // Retrying won't help since the stream is already errored // [!code highlight]
    throw new FatalError("Stream failed"); // [!code highlight]
  } // [!code highlight]
}

export async function streamErrorWorkflow() {
  "use workflow";

  const stream = await produceStream(); // Step succeeds // [!code highlight]
  await consumeStream(stream); // Consumer handles errors // [!code highlight]
}
```

<Callout type="info">
Los errores en las secuencias no desencadenan reintentos automáticos para el paso productor. Diseña tus consumidores de secuencia para manejar los errores apropiadamente. Dado que la secuencia ya está en un estado con error, reintentar el consumidor no ayudará: usa `FatalError` para fallar el flujo de trabajo inmediatamente.
</Callout>

## Documentación relacionada

- [`getWritable()` Referencia de API](/docs/api-reference/workflow/get-writable) - Obtener la secuencia escribible del flujo de trabajo
- [`sleep()` Referencia de API](/docs/api-reference/workflow/sleep) - Pausar la ejecución del flujo de trabajo por una duración
- [`start()` Referencia de API](/docs/api-reference/workflow-api/start) - Iniciar flujos de trabajo y acceder al objeto `Run`
- [`getRun()` Referencia de API](/docs/api-reference/workflow-api/get-run) - Recuperar ejecuciones y sus secuencias más tarde
- [DurableAgent](/docs/api-reference/workflow-ai/durable-agent) - Agentes de IA con soporte de streaming incorporado
- [Errores y reintentos](/docs/foundations/errors-and-retries) - Entender el manejo de errores y el comportamiento de reintentos
- [Serialización](/docs/foundations/serialization) - Entender qué tipos de datos se pueden pasar en los flujos de trabajo
- [Flujos de trabajo y pasos](/docs/foundations/workflows-and-steps) - Conceptos principales de la ejecución de flujos de trabajo