---
title: Flux en continu
---

Les workflows peuvent diffuser des données en temps réel vers les clients sans attendre que l'intégralité du workflow soit terminée. Cela permet de fournir des mises à jour de progression, du contenu généré par l'IA, des messages de journalisation et d'autres données incrémentielles pendant l'exécution des workflows.

## Commencer avec `getWritable()`

Chaque exécution de workflow dispose d'un flux writable par défaut dans lequel les steps peuvent écrire en utilisant [`getWritable()`](/docs/api-reference/workflow/get-writable). Les données écrites dans ce flux deviennent immédiatement disponibles pour les clients consommant la sortie du workflow.

```typescript title="workflows/simple-streaming.ts" lineNumbers
import { getWritable } from "workflow";

async function writeProgress(message: string) {
  "use step";

  // Steps can write to the run's default stream
  const writable = getWritable<string>(); // [!code highlight]
  const writer = writable.getWriter();
  await writer.write(message);
  writer.releaseLock();
}

export async function simpleStreamingWorkflow() {
  "use workflow";

  await writeProgress("Starting task...");
  await writeProgress("Processing data...");
  await writeProgress("Task complete!");
}
```

### Consommer le flux

Utilisez la propriété `readable` de l'objet `Run` pour consommer le flux depuis votre route API :

```typescript title="app/api/stream/route.ts" lineNumbers
import { start } from "workflow/api";
import { simpleStreamingWorkflow } from "./workflows/simple";

export async function POST() {
  const run = await start(simpleStreamingWorkflow);

  // Return the readable stream to the client
  return new Response(run.readable, {
    headers: { "Content-Type": "text/plain" }
  });
}
```

Lorsqu'un client effectue une requête à cet endpoint, il recevra chaque message au fur et à mesure qu'il est écrit, sans attendre la fin du workflow.

### Reprendre les flux depuis un point spécifique

Utilisez `run.getReadable({ startIndex })` pour reprendre un flux à partir d'une position spécifique. Ceci est utile pour se reconnecter après des délais d'attente ou des interruptions réseau :

```typescript title="app/api/resume-stream/[runId]/route.ts" lineNumbers
import { getRun } from "workflow/api";

export async function GET(
  request: Request,
  { params }: { params: Promise<{ runId: string }> }
) {
  const { runId } = await params;
  const { searchParams } = new URL(request.url);

  // Client provides the last chunk index they received
  const startIndexParam = searchParams.get("startIndex"); // [!code highlight]
  const startIndex = startIndexParam ? parseInt(startIndexParam, 10) : undefined; // [!code highlight]

  const run = getRun(runId);
  const stream = run.getReadable({ startIndex }); // [!code highlight]

  return new Response(stream, {
    headers: { "Content-Type": "text/plain" }
  });
}
```

Cela permet aux clients de se reconnecter et de continuer à recevoir les données là où ils s'étaient arrêtés, plutôt que de recommencer depuis le début.

## Les flux en tant que types de données

[`ReadableStream`](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream) et [`WritableStream`](https://developer.mozilla.org/en-US/docs/Web/API/WritableStream) sont des types standard de l'API Web Streams que Workflow DevKit rend sérialisables. Il ne s'agit pas de types personnalisés : ils respectent la norme Web — mais Workflow DevKit ajoute la capacité de les transmettre entre fonctions tout en maintenant leurs capacités de streaming.

Contrairement aux valeurs normales qui sont entièrement sérialisées dans le journal d'événements, les flux conservent leurs capacités de streaming lorsqu'ils sont passés entre fonctions.

**Propriétés clés :**
- Les références de flux peuvent être transmises entre les fonctions de workflow et les steps
- Les données de flux circulent directement sans être stockées dans le journal d'événements
- Les flux préservent leur état à travers les points de suspension du workflow

<Callout type="info">
**Comment les flux persistent à travers les suspensions de workflow**

Les flux dans Workflow DevKit sont reposés sur un stockage persistant et reprenable fourni par l'implémentation du "world". C'est ce qui permet aux flux de conserver leur état même lorsque les workflows sont suspendus et repris :

- **Déploiements Vercel** : Les flux sont soutenus par un flux performant basé sur Redis
- **Développement local** : Les morceaux de flux sont stockés dans le système de fichiers
</Callout>

### Passer des flux comme arguments

Puisque les flux sont des types de données sérialisables, vous n'avez pas besoin d'utiliser la fonction spéciale [`getWritable()`](/docs/api-reference/workflow/get-writable). Vous pouvez même faire transiter vos propres flux à travers les workflows en les passant comme arguments depuis l'extérieur vers les steps.

Voici un exemple de passage du flux du corps d'une requête à travers un workflow vers un step qui le traite :

```typescript title="app/api/upload/route.ts" lineNumbers
import { start } from "workflow/api";
import { streamProcessingWorkflow } from "./workflows/streaming";

export async function POST(request: Request) {
  // Streams can be passed as workflow arguments
  const run = await start(streamProcessingWorkflow, [request.body]); // [!code highlight]
  await run.result();

  return Response.json({ status: "complete" });
}
```

```typescript title="workflows/streaming.ts" lineNumbers
export async function streamProcessingWorkflow(
  inputStream: ReadableStream<Uint8Array> // [!code highlight]
) {
  "use workflow";

  // Workflow passes stream to step for processing
  const result = await processInputStream(inputStream); // [!code highlight]
  return { length: result.length };
}

async function processInputStream(input: ReadableStream<Uint8Array>) {
  "use step";

  // Step reads from the stream
  const chunks: Uint8Array[] = [];

  for await (const chunk of input) {
    chunks.push(chunk);
  }

  return Buffer.concat(chunks).toString("utf8");
}
```

## Limitation importante

<Callout type="info">
**Les flux ne peuvent pas être utilisés directement dans le contexte d'un workflow**

Vous ne pouvez pas lire ou écrire des flux directement au sein d'une fonction de workflow. Toutes les opérations sur les flux doivent se produire dans des fonctions de step.
</Callout>

Les fonctions de workflow doivent être déterministes pour supporter la relecture (replay). Étant donné que les flux contournent le journal d'événements pour des raisons de performance, lire les données d'un flux dans un workflow casserait la détermination — chaque relecture pourrait voir des données différentes. En exigeant que toutes les opérations sur les flux se produisent dans des steps, le framework garantit un comportement cohérent.

Pour en savoir plus sur la détermination et la relecture, voir [Workflows and Steps](/docs/foundations/workflows-and-steps).

```typescript title="workflows/bad-example.ts" lineNumbers
export async function badWorkflow() {
  "use workflow";

  const writable = getWritable<string>();

  // Cannot read/write streams in workflow context
  const writer = writable.getWriter(); // [!code highlight]
  await writer.write("data"); // [!code highlight]
}
```

```typescript title="workflows/good-example.ts" lineNumbers
export async function goodWorkflow() {
  "use workflow";

  // Delegate stream operations to steps
  await writeToStream("data");
}

async function writeToStream(data: string) {
  "use step";

  // Stream operations must happen in steps
  const writable = getWritable<string>();
  const writer = writable.getWriter();
  await writer.write(data);
  writer.releaseLock();
}
```

## Fluxs (namespaced) — Flux nommés

Utilisez `getWritable({ namespace: 'name' })` pour créer plusieurs flux indépendants pour différents types de données. Cela est utile lorsque vous souhaitez séparer les logs, les métriques, les sorties de données ou d'autres canaux distincts.

```typescript title="workflows/multi-stream.ts" lineNumbers
import { getWritable } from "workflow";

type LogEntry = { level: string; message: string };
type MetricEntry = { cpu: number; memory: number };

async function writeLogs() {
  "use step";

  const logs = getWritable<LogEntry>({ namespace: "logs" }); // [!code highlight]
  const writer = logs.getWriter();

  await writer.write({ level: "info", message: "Task started" });
  await writer.write({ level: "info", message: "Processing..." });

  writer.releaseLock();
}

async function writeMetrics() {
  "use step";

  const metrics = getWritable<MetricEntry>({ namespace: "metrics" }); // [!code highlight]
  const writer = metrics.getWriter();

  await writer.write({ cpu: 45, memory: 512 });
  await writer.write({ cpu: 52, memory: 520 });

  writer.releaseLock();
}

async function closeStreams() {
  "use step";

  await getWritable({ namespace: "logs" }).close();
  await getWritable({ namespace: "metrics" }).close();
}

export async function multiStreamWorkflow() {
  "use workflow";

  await writeLogs();
  await writeMetrics();
  await closeStreams();
}
```

### Consommer des flux nommés

Utilisez `run.getReadable({ namespace: 'name' })` pour accéder à des flux spécifiques :

```typescript title="app/api/multi-stream/route.ts" lineNumbers
import { start } from "workflow/api";
import { multiStreamWorkflow } from "./workflows/multi";

type LogEntry = { level: string; message: string };
type MetricEntry = { cpu: number; memory: number };

export async function POST(request: Request) {
  const run = await start(multiStreamWorkflow);

  // Access specific named streams // [!code highlight]
  const logs = run.getReadable<LogEntry>({ namespace: "logs" }); // [!code highlight]
  const metrics = run.getReadable<MetricEntry>({ namespace: "metrics" }); // [!code highlight]

  // Return the logs stream to the client
  return new Response(logs, {
    headers: { "Content-Type": "application/json" }
  });
}
```

## Modèles courants

### Mises à jour de progression pour les tâches longue durée

Envoyez des mises à jour de progression incrémentielles pour tenir les utilisateurs informés durant des workflows longs :

```typescript title="workflows/batch-processing.ts" lineNumbers
import { getWritable, sleep } from "workflow";

type ProgressUpdate = {
  item: string;
  progress: number;
  status: string;
};

async function processItem(
  item: string,
  current: number,
  total: number
) {
  "use step";

  const writable = getWritable<ProgressUpdate>(); // [!code highlight]
  const writer = writable.getWriter();

  // Simulate processing
  await new Promise(resolve => setTimeout(resolve, 1000));

  // Send progress update // [!code highlight]
  await writer.write({ // [!code highlight]
    item, // [!code highlight]
    progress: Math.round((current / total) * 100), // [!code highlight]
    status: "processing" // [!code highlight]
  }); // [!code highlight]

  writer.releaseLock();
}

async function finalizeProgress() {
  "use step";

  await getWritable().close();
}

export async function batchProcessingWorkflow(items: string[]) {
  "use workflow";

  for (let i = 0; i < items.length; i++) {
    await processItem(items[i], i + 1, items.length);
    await sleep("1s");
  }

  await finalizeProgress();
}
```

### Diffusion des réponses IA avec `DurableAgent`

Diffusez du contenu généré par l'IA en utilisant [`DurableAgent`](/docs/api-reference/workflow-ai/durable-agent) depuis `@workflow/ai`. Les outils peuvent également émettre des mises à jour de progression vers le même flux en utilisant des [data chunks](https://ai-sdk.dev/docs/ai-sdk-ui/streaming-data#streaming-custom-data) avec le type [`UIMessageChunk`](https://ai-sdk.dev/docs/ai-sdk-ui/stream-protocol) provenant du SDK IA :

```typescript title="workflows/ai-assistant.ts" lineNumbers
import { DurableAgent } from "@workflow/ai/agent";
import { getWritable } from "workflow";
import { z } from "zod";
import type { UIMessageChunk } from "ai";

async function searchFlights({ query }: { query: string }) {
  "use step";

  // Tools can emit progress updates to the stream
  const writable = getWritable<UIMessageChunk>(); // [!code highlight]
  const writer = writable.getWriter(); // [!code highlight]
  await writer.write({ // [!code highlight]
    type: "data-progress", // [!code highlight]
    data: { message: `Searching flights for ${query}...` }, // [!code highlight]
    transient: true, // [!code highlight]
  }); // [!code highlight]
  writer.releaseLock(); // [!code highlight]

  // ... search logic ...
  return { flights: [/* results */] };
}

export async function aiAssistantWorkflow(userMessage: string) {
  "use workflow";

  const agent = new DurableAgent({
    model: "anthropic/claude-haiku-4.5",
    system: "You are a helpful flight assistant.",
    tools: {
      searchFlights: {
        description: "Search for flights",
        inputSchema: z.object({ query: z.string() }),
        execute: searchFlights,
      },
    },
  });

  // LLM response will be streamed to the run's writable
  await agent.stream({
    messages: [{ role: "user", content: userMessage }],
    writable: getWritable<UIMessageChunk>(), // [!code highlight]
  });
}
```

```typescript title="app/api/ai-assistant/route.ts" lineNumbers
import { createUIMessageStreamResponse } from "ai";
import { start } from "workflow/api";
import { aiAssistantWorkflow } from "./workflows/ai";

export async function POST(request: Request) {
  const { message } = await request.json();

  const run = await start(aiAssistantWorkflow, [message]);

  return createUIMessageStreamResponse({
    stream: run.readable,
  });
}
```

<Callout type="info">
Pour une implémentation complète, consultez l'[exemple de réservation de vols](https://github.com/vercel/workflow-examples/tree/main/flight-booking-app) qui démontre la diffusion de réponses IA avec des mises à jour de progression des outils.
</Callout>

### Streaming entre étapes

Un step produit un flux et un autre step le consomme :

```typescript title="workflows/stream-pipeline.ts" lineNumbers
export async function streamPipelineWorkflow() {
  "use workflow";

  // Streams can be passed between steps
  const stream = await generateData(); // [!code highlight]
  const results = await consumeData(stream); // [!code highlight]

  return { count: results.length };
}

async function generateData(): Promise<ReadableStream<number>> {
  "use step";

  // Producer step creates a stream
  return new ReadableStream<number>({
    start(controller) {
      for (let i = 0; i < 10; i++) {
        controller.enqueue(i);
      }
      controller.close();
    }
  });
}

async function consumeData(readable: ReadableStream<number>) {
  "use step";

  // Consumer step reads from the stream
  const values: number[] = [];
  for await (const value of readable) {
    values.push(value);
  }
  return values;
}
```

### Traiter de gros fichiers sans surcharge mémoire

Traitez de gros fichiers en faisant circuler les morceaux via des steps de transformation :

```typescript title="workflows/file-processing.ts" lineNumbers
export async function fileProcessingWorkflow(fileUrl: string) {
  "use workflow";

  // Chain streams through multiple processing steps
  const rawStream = await downloadFile(fileUrl); // [!code highlight]
  const processedStream = await transformData(rawStream); // [!code highlight]
  await uploadResult(processedStream); // [!code highlight]
}

async function downloadFile(url: string): Promise<ReadableStream<Uint8Array>> {
  "use step";
  const response = await fetch(url);
  return response.body!;
}

async function transformData(input: ReadableStream<Uint8Array>): Promise<ReadableStream<Uint8Array>> {
  "use step";

  // Transform stream chunks without loading entire file into memory
  return input.pipeThrough(new TransformStream<Uint8Array, Uint8Array>({
    transform(chunk, controller) {
      // Process each chunk individually
      controller.enqueue(chunk);
    }
  }));
}

async function uploadResult(stream: ReadableStream<Uint8Array>) {
  "use step";
  await fetch("https://storage.example.com/upload", {
    method: "POST",
    body: stream,
  });
}
```

## Bonnes pratiques

**Libérez correctement les verrous :**

```typescript lineNumbers
const writer = writable.getWriter();
try {
  await writer.write(data);
} finally {
  writer.releaseLock(); // Always release
}
```

<Callout type="info">
Les verrous de flux acquis dans un step ne s'appliquent qu'au sein de ce step, pas entre différents steps. Cela permet à plusieurs writers d'écrire simultanément dans le même flux.
</Callout>

<Callout type="info">
Si un verrou n'est pas libéré, le processus du step ne peut pas se terminer. Même si le step renvoie et que le workflow continue, le processus sous-jacent restera actif jusqu'à son expiration.
</Callout>

**Fermez les flux lorsque vous avez terminé :**

```typescript lineNumbers
async function finalizeStream() {
  "use step";

  await getWritable().close(); // Signal completion
}
```

Les flux sont automatiquement fermés lorsque l'exécution du workflow se termine, mais les fermer explicitement signale la complétion aux consommateurs plus tôt.

**Utilisez des flux typés pour la sécurité des types :**

```typescript lineNumbers
const writable = getWritable<MyDataType>();
const writer = writable.getWriter();
await writer.write({ /* typed data */ });
```

## Échecs de flux

Lorsqu'un step renvoie un flux, le step est considéré comme réussi une fois qu'il a renvoyé, même si le flux rencontre ensuite une erreur. Le workflow ne relancera pas automatiquement le step. Le consommateur du flux doit gérer les erreurs de manière appropriée. Pour plus d'informations sur le comportement de retry, voir [Errors and Retries](/docs/foundations/errors-and-retries).

```typescript title="workflows/stream-error-handling.ts" lineNumbers
import { FatalError } from "workflow";

async function produceStream(): Promise<ReadableStream<number>> {
  "use step";

  // Step succeeds once it returns the stream
  return new ReadableStream<number>({
    start(controller) {
      controller.enqueue(1);
      controller.enqueue(2);
      // Error occurs after step has completed // [!code highlight]
      controller.error(new Error("Stream failed")); // [!code highlight]
    }
  });
}

async function consumeStream(stream: ReadableStream<number>) {
  "use step";

  try { // [!code highlight]
    for await (const value of stream) {
      console.log(value);
    }
  } catch (error) { // [!code highlight]
    // Retrying won't help since the stream is already errored // [!code highlight]
    throw new FatalError("Stream failed"); // [!code highlight]
  } // [!code highlight]
}

export async function streamErrorWorkflow() {
  "use workflow";

  const stream = await produceStream(); // Step succeeds // [!code highlight]
  await consumeStream(stream); // Consumer handles errors // [!code highlight]
}
```

<Callout type="info">
Les erreurs de flux ne déclenchent pas de relances automatiques pour le step producteur. Concevez vos consommateurs de flux pour gérer les erreurs de manière appropriée. Puisque le flux est déjà en état d'erreur, relancer le consommateur n'aidera pas — utilisez `FatalError` pour échouer immédiatement le workflow.
</Callout>

## Documentation connexe

- [`getWritable()` API Reference](/docs/api-reference/workflow/get-writable) - Obtenir le flux writable du workflow
- [`sleep()` API Reference](/docs/api-reference/workflow/sleep) - Mettre en pause l'exécution du workflow pendant une durée
- [`start()` API Reference](/docs/api-reference/workflow-api/start) - Démarrer des workflows et accéder à l'objet `Run`
- [`getRun()` API Reference](/docs/api-reference/workflow-api/get-run) - Récupérer des exécutions et leurs flux ultérieurement
- [DurableAgent](/docs/api-reference/workflow-ai/durable-agent) - Agents IA avec support de streaming intégré
- [Errors and Retries](/docs/foundations/errors-and-retries) - Comprendre la gestion des erreurs et le comportement de retry
- [Serialization](/docs/foundations/serialization) - Comprendre quels types de données peuvent être passés dans les workflows
- [Workflows and Steps](/docs/foundations/workflows-and-steps) - Concepts principaux de l'exécution des workflows